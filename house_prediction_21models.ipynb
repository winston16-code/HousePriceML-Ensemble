{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e3dde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 11:54:04,743 - INFO - ================================================================================\n",
      "2025-11-26 11:54:04,743 - INFO - House Price Prediction - Multi-Modal Deep Learning\n",
      "2025-11-26 11:54:04,743 - INFO - ================================================================================\n",
      "2025-11-26 11:54:04,743 - INFO - Configuration initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using GPU: NVIDIA GeForce RTX 4060\n",
      "  Memory: 8.59 GB\n",
      "‚úì CUDA optimizations enabled\n",
      "‚úì Mixed precision training (FP16) supported\n",
      "‚úì Random seed set to 42\n",
      "\n",
      "================================================================================\n",
      "SYSTEM INFORMATION\n",
      "================================================================================\n",
      "PyTorch Version: 2.7.1+cu118\n",
      "CUDA Available: True\n",
      "CUDA Version: 11.8\n",
      "cuDNN Version: 90100\n",
      "Device: cuda\n",
      "Number of CPU cores: 24\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STAGE 1: IMPORTS AND ENVIRONMENT SETUP\n",
    "# ============================================================================\n",
    "\n",
    "# Core Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning Frameworks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed precision training\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# Advanced Vision Models\n",
    "import timm  # For state-of-the-art vision architectures\n",
    "from efficientnet_pytorch import EfficientNet  # Efficient architectures\n",
    "\n",
    "# Machine Learning & Preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, PowerTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import IsolationForest  # Outlier detection\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Utilities\n",
    "import time\n",
    "from collections import defaultdict, Counter\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Augmentation (Advanced)\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Model Interpretability\n",
    "try:\n",
    "    import shap  # For model explainability\n",
    "    from captum.attr import IntegratedGradients, Saliency  # For feature attribution\n",
    "    INTERPRETABILITY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    INTERPRETABILITY_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è Interpretability libraries not available. Install: pip install shap captum\")\n",
    "\n",
    "# ============================================================================\n",
    "# DEVICE SETUP & OPTIMIZATION\n",
    "# ============================================================================\n",
    "\n",
    "# Set device with fallback\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f'‚úì Using GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n",
    "elif torch.backends.mps.is_available():  # Apple Silicon\n",
    "    device = torch.device('mps')\n",
    "    print(f'‚úì Using Apple MPS (Metal Performance Shaders)')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f'‚ö†Ô∏è Using CPU (training will be slower)')\n",
    "\n",
    "# Performance optimizations\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True  # Auto-tune convolution algorithms\n",
    "    torch.backends.cudnn.deterministic = False  # Faster but non-deterministic\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    print(f'‚úì CUDA optimizations enabled')\n",
    "    \n",
    "    # Check for mixed precision support\n",
    "    if torch.cuda.get_device_capability()[0] >= 7:  # Volta or newer\n",
    "        print(f'‚úì Mixed precision training (FP16) supported')\n",
    "        USE_AMP = True\n",
    "    else:\n",
    "        print(f'‚ö†Ô∏è GPU does not support efficient mixed precision')\n",
    "        USE_AMP = False\n",
    "else:\n",
    "    USE_AMP = False\n",
    "\n",
    "# ============================================================================\n",
    "# REPRODUCIBILITY SETUP\n",
    "# ============================================================================\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed: int = SEED):\n",
    "    \"\"\"Set seeds for reproducibility across all libraries\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    # Python hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    # Additional reproducibility (slower but deterministic)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n",
    "print(f'‚úì Random seed set to {SEED}')\n",
    "\n",
    "# ============================================================================\n",
    "# LOGGING SETUP\n",
    "# ============================================================================\n",
    "\n",
    "def setup_logging(log_dir: str = 'logs'):\n",
    "    \"\"\"Setup logging for training monitoring\"\"\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    log_file = os.path.join(log_dir, f'training_{timestamp}.log')\n",
    "    \n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "logger = setup_logging()\n",
    "logger.info('='*80)\n",
    "logger.info('House Price Prediction - Multi-Modal Deep Learning')\n",
    "logger.info('='*80)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION CLASS\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration for the entire pipeline\"\"\"\n",
    "    \n",
    "    # Paths\n",
    "    data_dir: str = 'data'\n",
    "    image_dir: str = 'data/images'\n",
    "    excel_path: str = 'data/properties.xlsx'\n",
    "    output_dir: str = 'outputs'\n",
    "    model_save_dir: str = 'models'\n",
    "    \n",
    "    # Model Architecture\n",
    "    image_model: str = 'efficientnet_b4'  # Options: efficientnet_b0-b7, resnet50, convnext_tiny\n",
    "    pretrained: bool = True\n",
    "    freeze_backbone_epochs: int = 5  # Freeze feature extractor initially\n",
    "    \n",
    "    # Training Hyperparameters\n",
    "    batch_size: int = 16\n",
    "    num_epochs: int = 100\n",
    "    learning_rate: float = 1e-4\n",
    "    weight_decay: float = 1e-4\n",
    "    early_stopping_patience: int = 15\n",
    "    gradient_clip: float = 1.0\n",
    "    \n",
    "    # Image Processing\n",
    "    img_size: int = 384  # Higher resolution for better feature extraction\n",
    "    \n",
    "    # Data Split\n",
    "    test_size: float = 0.15\n",
    "    val_size: float = 0.15\n",
    "    \n",
    "    # Cross-Validation\n",
    "    use_kfold: bool = True\n",
    "    n_folds: int = 5\n",
    "    \n",
    "    # Mixed Precision\n",
    "    use_amp: bool = USE_AMP\n",
    "    \n",
    "    # Ensemble\n",
    "    use_ensemble: bool = True\n",
    "    num_ensemble_models: int = 3\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        for dir_path in [self.output_dir, self.model_save_dir, 'logs']:\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "logger.info(f'Configuration initialized')\n",
    "\n",
    "# ============================================================================\n",
    "# DISPLAY SYSTEM INFO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SYSTEM INFORMATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"cuDNN Version: {torch.backends.cudnn.version()}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Number of CPU cores: {os.cpu_count()}\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d23692d",
   "metadata": {},
   "source": [
    "Stage 2: Load Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d41eb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:/Users/LEGION/Desktop/big_data/property_cleaned.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/LEGION/Desktop/big_data/property_cleaned.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m csv_file = \u001b[33m'\u001b[39m\u001b[33mC:/Users/LEGION/Desktop/big_data/property_cleaned.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLoading data from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m‚úì Loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows from cleaned CSV\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Display columns info\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:/Users/LEGION/Desktop/big_data/property_cleaned.csv'"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "csv_file = 'C:/Users/LEGION/Desktop/big_data/property_cleaned.csv'\n",
    "print(f'Loading data from: {csv_file}')\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "print(f'‚úì Loaded {len(df)} rows from cleaned CSV')\n",
    "\n",
    "# Display columns info\n",
    "print(f'\\nColumns in dataset: {df.columns.tolist()}')\n",
    "\n",
    "# Prepare image paths\n",
    "image_dir = Path('C:/Users/LEGION/Desktop/big_data/images')\n",
    "print(f'Image directory: {image_dir}')\n",
    "\n",
    "# Check if images exist and create image paths\n",
    "df['image_path'] = df['id'].apply(lambda x: image_dir / f'{x}.jpg')\n",
    "print(f'Created image paths for {len(df)} properties')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2edc5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAST DATASET & DATALOADER CREATION\n",
      "================================================================================\n",
      "\n",
      "‚úì Price scaler created\n",
      "‚úì Dataset class defined\n",
      "‚úì Transforms defined\n",
      "‚úì Data split: 1129 train, 242 val, 242 test\n",
      "‚úì Datasets created: 1129 / 242 / 242\n",
      "\n",
      "‚öôÔ∏è  Settings: batch_size=16, num_workers=0\n",
      "‚úì DataLoaders created\n",
      "   Train: 70 batches\n",
      "   Val: 8 batches\n",
      "   Test: 8 batches\n",
      "\n",
      "üß™ Quick test...\n",
      "‚úÖ Working! Shapes: torch.Size([16, 3, 224, 224]), torch.Size([16, 5]), torch.Size([16])\n",
      "\n",
      "================================================================================\n",
      "‚úÖ COMPLETE - Ready for training!\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FAST VERSION - STAGES 3 & 4 (Should complete in <1 minute)\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FAST DATASET & DATALOADER CREATION\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ===== 1. Price Scaler =====\n",
    "price_scaler = StandardScaler()\n",
    "price_scaler.fit(df[['price(USD)']])\n",
    "print(\"‚úì Price scaler created\")\n",
    "\n",
    "# ===== 2. Simple Dataset Class (NO fancy features) =====\n",
    "class FastHousePriceDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None, price_scaler=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.transform = transform\n",
    "        self.price_scaler = price_scaler\n",
    "        \n",
    "        # Simple features\n",
    "        numeric_cols = ['building_area(m¬≤)', 'land_area(m¬≤)', 'bedrooms', 'bathrooms']\n",
    "        location_encoder = LabelEncoder()\n",
    "        df['location_encoded'] = location_encoder.fit_transform(df['location'].fillna('Unknown'))\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        self.features = scaler.fit_transform(df[numeric_cols + ['location_encoded']].fillna(0))\n",
    "        self.prices = torch.FloatTensor(df['price(USD)'].values)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image\n",
    "        img_path = self.image_dir / f\"{row['id']}.jpg\"\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except:\n",
    "            image = Image.new('RGB', (224, 224), color=(128, 128, 128))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        features = torch.FloatTensor(self.features[idx])\n",
    "        \n",
    "        price = float(row['price(USD)'])\n",
    "        if self.price_scaler:\n",
    "            price = self.price_scaler.transform([[price]])[0][0]\n",
    "        \n",
    "        return image, features, torch.tensor(price, dtype=torch.float32)\n",
    "\n",
    "print(\"‚úì Dataset class defined\")\n",
    "\n",
    "# ===== 3. Simple Transforms =====\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"‚úì Transforms defined\")\n",
    "\n",
    "# ===== 4. Split Data =====\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"‚úì Data split: {len(train_df)} train, {len(val_df)} val, {len(test_df)} test\")\n",
    "\n",
    "# ===== 5. Create Datasets =====\n",
    "train_dataset = FastHousePriceDataset(train_df, image_dir, train_transform, price_scaler)\n",
    "val_dataset = FastHousePriceDataset(val_df, image_dir, val_transform, price_scaler)\n",
    "test_dataset = FastHousePriceDataset(test_df, image_dir, val_transform, price_scaler)\n",
    "\n",
    "print(f\"‚úì Datasets created: {len(train_dataset)} / {len(val_dataset)} / {len(test_dataset)}\")\n",
    "\n",
    "# ===== 6. Create DataLoaders (SIMPLE - NO fancy features) =====\n",
    "\n",
    "# Determine batch size\n",
    "if torch.cuda.is_available():\n",
    "    batch_size = 16\n",
    "    num_workers = 0  # ‚Üê KEY FIX: Set to 0 for Windows/debugging\n",
    "else:\n",
    "    batch_size = 4\n",
    "    num_workers = 0\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Settings: batch_size={batch_size}, num_workers={num_workers}\")\n",
    "\n",
    "# Create loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  # ‚Üê Simple shuffle, no weighted sampler\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size * 2,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size * 2,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "print(f\"‚úì DataLoaders created\")\n",
    "print(f\"   Train: {len(train_loader)} batches\")\n",
    "print(f\"   Val: {len(val_loader)} batches\")\n",
    "print(f\"   Test: {len(test_loader)} batches\")\n",
    "\n",
    "# ===== 7. MINIMAL Test (should be instant) =====\n",
    "print(\"\\nüß™ Quick test...\")\n",
    "try:\n",
    "    batch = next(iter(train_loader))\n",
    "    images, features, prices = batch\n",
    "    print(f\"‚úÖ Working! Shapes: {images.shape}, {features.shape}, {prices.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ COMPLETE - Ready for training!\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c68962",
   "metadata": {},
   "source": [
    "Stage 3: Data Preparation and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e203cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Price scaler created for normalization\n",
      "Train: 1129, Val: 242, Test: 242\n",
      "‚úÖ Datasets created:\n",
      "   Train dataset: 1129 samples\n",
      "   Val dataset: 242 samples\n",
      "   Test dataset: 242 samples\n",
      "‚úÖ Sample shapes - Images: torch.Size([3, 224, 224]), Features: torch.Size([5]), Price: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STAGE 3: DATA PREPARATION AND SPLIT (COMPLETE VERSION)\n",
    "# ============================================================================\n",
    "\n",
    "# Create price scaler for normalization\n",
    "price_scaler = StandardScaler()\n",
    "price_scaler.fit(df[['price(USD)']])\n",
    "print(f'‚úì Price scaler created for normalization')\n",
    "\n",
    "# Dataset class\n",
    "class HousePriceDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None, include_features=True, price_scaler=None):\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.transform = transform\n",
    "        self.include_features = include_features\n",
    "        self.price_scaler = price_scaler\n",
    "        \n",
    "        # Prepare numeric features\n",
    "        self.numeric_features = ['building_area(m¬≤)', 'land_area(m¬≤)', 'bedrooms', 'bathrooms']\n",
    "        \n",
    "        # Prepare location encoding\n",
    "        self.location_encoder = LabelEncoder()\n",
    "        self.df['location_encoded'] = self.location_encoder.fit_transform(df['location'].fillna('Unknown'))\n",
    "        \n",
    "        # Normalize numeric features\n",
    "        self.scaler = StandardScaler()\n",
    "        feature_cols = self.numeric_features + ['location_encoded']\n",
    "        self.feature_array = self.scaler.fit_transform(self.df[feature_cols].fillna(0))\n",
    "        \n",
    "        # Store prices for sampling\n",
    "        self.prices = df['price(USD)'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image\n",
    "        img_path = self.image_dir / f\"{row['id']}.jpg\"\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            # If image fails to load, create a black image\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get features (ensure Float32)\n",
    "        features = torch.FloatTensor(self.feature_array[idx])\n",
    "        \n",
    "        # Get target (price) - normalize if scaler is provided\n",
    "        raw_price = float(row['price(USD)'])\n",
    "        if self.price_scaler is not None:\n",
    "            # Normalize the price\n",
    "            price_normalized = self.price_scaler.transform([[raw_price]])[0][0]\n",
    "            price = torch.tensor(price_normalized, dtype=torch.float32)\n",
    "        else:\n",
    "            price = torch.tensor(raw_price, dtype=torch.float32)\n",
    "        \n",
    "        if self.include_features:\n",
    "            return image, features, price\n",
    "        else:\n",
    "            return image, price\n",
    "\n",
    "# Data transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Split data\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f'Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}')\n",
    "\n",
    "# ============================================================================\n",
    "# ACTUALLY CREATE THE DATASETS (THIS WAS MISSING!)\n",
    "# ============================================================================\n",
    "\n",
    "# Create datasets with price scaler\n",
    "train_dataset = HousePriceDataset(train_df, image_dir, transform=train_transform, price_scaler=price_scaler)\n",
    "val_dataset = HousePriceDataset(val_df, image_dir, transform=val_transform, price_scaler=price_scaler)\n",
    "test_dataset = HousePriceDataset(test_df, image_dir, transform=val_transform, price_scaler=price_scaler)\n",
    "\n",
    "print('‚úÖ Datasets created:')\n",
    "print(f'   Train dataset: {len(train_dataset)} samples')\n",
    "print(f'   Val dataset: {len(val_dataset)} samples')  \n",
    "print(f'   Test dataset: {len(test_dataset)} samples')\n",
    "\n",
    "# Quick test\n",
    "sample = train_dataset[0]\n",
    "print(f'‚úÖ Sample shapes - Images: {sample[0].shape}, Features: {sample[1].shape}, Price: {sample[2].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727a90a2",
   "metadata": {},
   "source": [
    "Stage 4: Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97043a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "================================================================================\n",
      "üì¶ CREATING DATALOADERS\n",
      "================================================================================\n",
      "‚öôÔ∏è  Settings:\n",
      "   Batch size: 16\n",
      "   Workers: 2\n",
      "   Device: cuda\n",
      "\n",
      "‚úÖ Data loaders created:\n",
      "   Train batches: 70\n",
      "   Val batches: 16\n",
      "   Test batches: 16\n",
      "\n",
      "üß™ Testing data loading...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STAGE 4: SIMPLIFIED DATALOADERS (WORKS WITH STAGE 3)\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "def create_simple_dataloaders(train_dataset, val_dataset, test_dataset):\n",
    "    \"\"\"\n",
    "    Create simple but optimized dataloaders without complex dependencies\n",
    "    \"\"\"\n",
    "    print(f'\\n{\"=\"*80}')\n",
    "    print(f'üì¶ CREATING DATALOADERS')\n",
    "    print(f'{\"=\"*80}')\n",
    "    \n",
    "    # Determine optimal settings\n",
    "    if torch.cuda.is_available():\n",
    "        batch_size = 16  # Good for RTX 4060\n",
    "        num_workers = min(4, os.cpu_count() - 1) if os.cpu_count() else 2\n",
    "        if os.name == 'nt':  # Windows\n",
    "            num_workers = min(2, num_workers)\n",
    "    else:\n",
    "        batch_size = 8\n",
    "        num_workers = 2\n",
    "    \n",
    "    print(f'‚öôÔ∏è  Settings:')\n",
    "    print(f'   Batch size: {batch_size}')\n",
    "    print(f'   Workers: {num_workers}')\n",
    "    print(f'   Device: {device}')\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,  # Simple shuffle instead of weighted sampler\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    print(f'\\n‚úÖ Data loaders created:')\n",
    "    print(f'   Train batches: {len(train_loader)}')\n",
    "    print(f'   Val batches: {len(val_loader)}')\n",
    "    print(f'   Test batches: {len(test_loader)}')\n",
    "    \n",
    "    # Test data loading\n",
    "    print(f'\\nüß™ Testing data loading...')\n",
    "    try:\n",
    "        test_batch = next(iter(train_loader))\n",
    "        images, features, prices = test_batch\n",
    "        print(f'‚úÖ Data loading works!')\n",
    "        print(f'   Batch shape - Images: {images.shape}, Features: {features.shape}, Prices: {prices.shape}')\n",
    "        print(f'   Price range: {prices.min().item():.4f} to {prices.max().item():.4f}')\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Data loading error: {e}')\n",
    "        raise\n",
    "    \n",
    "    print(f'{\"=\"*80}\\n')\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# ============================================================================\n",
    "# ACTUALLY CREATE THE DATALOADERS (THIS WAS MISSING!)\n",
    "# ============================================================================\n",
    "\n",
    "# Create dataloaders using the datasets from Stage 3\n",
    "train_loader, val_loader, test_loader = create_simple_dataloaders(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset, \n",
    "    test_dataset=test_dataset\n",
    ")\n",
    "\n",
    "print('üéâ Stage 4 complete - DataLoaders ready for training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef1680",
   "metadata": {},
   "source": [
    "Stage 5: ULTRA-STABLE Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac627f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STAGE 5: ULTRA-STABLE MODEL ARCHITECTURE\n",
      "================================================================================\n",
      "\n",
      "\n",
      "üß™ Testing model creation...\n",
      "‚úì Model created: efficientnet_b0\n",
      "  Image features: 1280\n",
      "  Tabular features: 128\n",
      "  Fusion dim: 1408\n",
      "  Total parameters: 4,912,509\n",
      "\n",
      "‚úÖ Model moved to cuda\n",
      "\n",
      "üß™ Testing forward pass...\n",
      "‚úÖ Forward pass successful!\n",
      "   Input: torch.Size([2, 3, 224, 224]), torch.Size([2, 5])\n",
      "   Output: torch.Size([2])\n",
      "   Output range: [0.000, 0.000]\n",
      "‚úÖ No NaN/Inf detected\n",
      "\n",
      "================================================================================\n",
      "‚úÖ STAGE 5 COMPLETE - MODEL READY\n",
      "================================================================================\n",
      "\n",
      "üìä Model Summary:\n",
      "   Architecture: efficientnet_b0\n",
      "   Image features: 1280\n",
      "   Tabular features: 128\n",
      "   Total parameters: 4,912,509\n",
      "   Trainable: 4,912,509\n",
      "\n",
      "üöÄ Ready for training!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE WORKING STAGE 5 - ULTRA-STABLE MODEL\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 5: ULTRA-STABLE MODEL ARCHITECTURE\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# STABILITY UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "class SafeBatchNorm1d(nn.BatchNorm1d):\n",
    "    \"\"\"BatchNorm that prevents NaN/Inf\"\"\"\n",
    "    def forward(self, x):\n",
    "        x = torch.clamp(x, min=-1e4, max=1e4)\n",
    "        output = super().forward(x)\n",
    "        if not torch.isfinite(output).all():\n",
    "            return torch.nan_to_num(output, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        return output\n",
    "\n",
    "class GradientClipLinear(nn.Linear):\n",
    "    \"\"\"Linear layer with built-in gradient clipping\"\"\"\n",
    "    def __init__(self, *args, max_grad_norm=1.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.weight.register_hook(\n",
    "            lambda grad: torch.clamp(grad, -max_grad_norm, max_grad_norm)\n",
    "        )\n",
    "        if self.bias is not None:\n",
    "            self.bias.register_hook(\n",
    "                lambda grad: torch.clamp(grad, -max_grad_norm, max_grad_norm)\n",
    "            )\n",
    "\n",
    "# ============================================================================\n",
    "# PREDICTION HEAD (FIXED)\n",
    "# ============================================================================\n",
    "\n",
    "class UltraStablePredictionHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dims: Tuple[int, ...] = (512, 256, 128, 64),\n",
    "        dropout: float = 0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(GradientClipLinear(prev_dim, hidden_dim))\n",
    "            layers.append(SafeBatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.ReLU(inplace=False))\n",
    "            dropout_rate = dropout * (1.0 - 0.2 * i / len(hidden_dims))\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(*layers)  # ‚Üê FIX: Use *layers\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], 1)\n",
    "        nn.init.normal_(self.output_layer.weight, mean=0.0, std=0.001)\n",
    "        nn.init.constant_(self.output_layer.bias, 0.0)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.feature_extractor(x)\n",
    "        output = self.output_layer(features)\n",
    "        output = torch.clamp(output, min=-15.0, max=15.0)\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN MODEL\n",
    "# ============================================================================\n",
    "\n",
    "class UltraStableHousePriceModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone_name: str = 'efficientnet_b0',\n",
    "        num_tabular_features: int = 5,\n",
    "        dropout: float = 0.3,\n",
    "        pretrained: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        # Create backbone\n",
    "        self.backbone, self.image_feature_dim = self._create_backbone(\n",
    "            backbone_name, pretrained\n",
    "        )\n",
    "        \n",
    "        # Tabular encoder\n",
    "        self.tabular_encoder = nn.Sequential(\n",
    "            GradientClipLinear(num_tabular_features, 64, max_grad_norm=1.0),\n",
    "            SafeBatchNorm1d(64),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Dropout(0.2),\n",
    "            GradientClipLinear(64, 128, max_grad_norm=1.0),\n",
    "            SafeBatchNorm1d(128),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.tabular_feature_dim = 128\n",
    "        \n",
    "        # Fusion (simple concatenation)\n",
    "        fusion_dim = self.image_feature_dim + self.tabular_feature_dim\n",
    "        \n",
    "        # Prediction head\n",
    "        self.prediction_head = UltraStablePredictionHead(\n",
    "            input_dim=fusion_dim,\n",
    "            hidden_dims=(512, 256, 128, 64),\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "        \n",
    "        print(f\"‚úì Model created: {backbone_name}\")\n",
    "        print(f\"  Image features: {self.image_feature_dim}\")\n",
    "        print(f\"  Tabular features: {self.tabular_feature_dim}\")\n",
    "        print(f\"  Fusion dim: {fusion_dim}\")\n",
    "        print(f\"  Total parameters: {sum(p.numel() for p in self.parameters()):,}\")\n",
    "    \n",
    "    def _create_backbone(self, backbone_name: str, pretrained: bool) -> Tuple[nn.Module, int]:\n",
    "        backbone_name = backbone_name.lower()\n",
    "        \n",
    "        if 'efficientnet_b0' in backbone_name:\n",
    "            backbone = models.efficientnet_b0(\n",
    "                weights=models.EfficientNet_B0_Weights.DEFAULT if pretrained else None\n",
    "            )\n",
    "            feature_dim = 1280\n",
    "            backbone.classifier = nn.Identity()\n",
    "            \n",
    "        elif 'efficientnet_b3' in backbone_name:\n",
    "            backbone = models.efficientnet_b3(\n",
    "                weights=models.EfficientNet_B3_Weights.DEFAULT if pretrained else None\n",
    "            )\n",
    "            feature_dim = 1536\n",
    "            backbone.classifier = nn.Identity()\n",
    "            \n",
    "        elif 'resnet50' in backbone_name:\n",
    "            backbone = models.resnet50(\n",
    "                weights=models.ResNet50_Weights.DEFAULT if pretrained else None\n",
    "            )\n",
    "            feature_dim = 2048\n",
    "            backbone.fc = nn.Identity()\n",
    "            \n",
    "        elif 'mobilenet_v2' in backbone_name:\n",
    "            backbone = models.mobilenet_v2(\n",
    "                weights=models.MobileNet_V2_Weights.DEFAULT if pretrained else None\n",
    "            )\n",
    "            feature_dim = 1280\n",
    "            backbone.classifier = nn.Identity()\n",
    "            \n",
    "        elif 'densenet121' in backbone_name:\n",
    "            backbone = models.densenet121(\n",
    "                weights=models.DenseNet121_Weights.DEFAULT if pretrained else None\n",
    "            )\n",
    "            feature_dim = 1024\n",
    "            backbone.classifier = nn.Identity()\n",
    "        \n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Unknown backbone '{backbone_name}', using EfficientNet-B0\")\n",
    "            backbone = models.efficientnet_b0(\n",
    "                weights=models.EfficientNet_B0_Weights.DEFAULT if pretrained else None\n",
    "            )\n",
    "            feature_dim = 1280\n",
    "            backbone.classifier = nn.Identity()\n",
    "        \n",
    "        return backbone, feature_dim\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight, gain=0.5)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, images: torch.Tensor, tabular_features: torch.Tensor) -> torch.Tensor:\n",
    "        # Extract image features\n",
    "        if not torch.isfinite(images).all():\n",
    "            images = torch.nan_to_num(images, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "            images = torch.clamp(images, min=0.0, max=1.0)\n",
    "        \n",
    "        image_features = self.backbone(images)\n",
    "        if len(image_features.shape) > 2:\n",
    "            image_features = torch.flatten(image_features, 1)\n",
    "        \n",
    "        if not torch.isfinite(image_features).all():\n",
    "            image_features = torch.nan_to_num(image_features, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        \n",
    "        # Process tabular features\n",
    "        if not torch.isfinite(tabular_features).all():\n",
    "            tabular_features = torch.nan_to_num(tabular_features, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        \n",
    "        tabular_encoded = self.tabular_encoder(tabular_features)\n",
    "        \n",
    "        if not torch.isfinite(tabular_encoded).all():\n",
    "            tabular_encoded = torch.nan_to_num(tabular_encoded, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        \n",
    "        # Fuse features (concatenation)\n",
    "        fused_features = torch.cat([image_features, tabular_encoded], dim=1)\n",
    "        \n",
    "        if not torch.isfinite(fused_features).all():\n",
    "            fused_features = torch.nan_to_num(fused_features, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        \n",
    "        # Predict price\n",
    "        predictions = self.prediction_head(fused_features)\n",
    "        \n",
    "        if not torch.isfinite(predictions).all():\n",
    "            predictions = torch.nan_to_num(predictions, nan=0.0, posinf=10.0, neginf=-10.0)\n",
    "            predictions = torch.clamp(predictions, min=-10.0, max=15.0)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# ============================================================================\n",
    "# TEST THE MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüß™ Testing model creation...\")\n",
    "\n",
    "# Create model\n",
    "model = UltraStableHousePriceModel(\n",
    "    backbone_name='efficientnet_b0',\n",
    "    num_tabular_features=5,\n",
    "    dropout=0.3,\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "print(f\"\\n‚úÖ Model moved to {device}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\nüß™ Testing forward pass...\")\n",
    "dummy_images = torch.randn(2, 3, 224, 224).to(device)\n",
    "dummy_features = torch.randn(2, 5).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_images, dummy_features)\n",
    "\n",
    "print(f\"‚úÖ Forward pass successful!\")\n",
    "print(f\"   Input: {dummy_images.shape}, {dummy_features.shape}\")\n",
    "print(f\"   Output: {output.shape}\")\n",
    "print(f\"   Output range: [{output.min():.3f}, {output.max():.3f}]\")\n",
    "\n",
    "assert torch.isfinite(output).all(), \"‚ùå NaN/Inf in output!\"\n",
    "print(f\"‚úÖ No NaN/Inf detected\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ STAGE 5 COMPLETE - MODEL READY\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"üìä Model Summary:\")\n",
    "print(f\"   Architecture: {model.backbone_name}\")\n",
    "print(f\"   Image features: {model.image_feature_dim}\")\n",
    "print(f\"   Tabular features: {model.tabular_feature_dim}\")\n",
    "print(f\"   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   Trainable: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(\"\\nüöÄ Ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b64e1",
   "metadata": {},
   "source": [
    "Stage 6: ULTRA-STABLE Training Function with Gradient Safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2c79a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "UltraStableHousePriceModel.__init__() got an unexpected keyword argument 'fusion_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 687\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m    682\u001b[39m \u001b[38;5;66;03m# USAGE EXAMPLE\u001b[39;00m\n\u001b[32m    683\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m    685\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    686\u001b[39m     \u001b[38;5;66;03m# Create stable model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m     model = \u001b[43mcreate_stable_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackbone_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mefficientnet_b0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# SAFE BACKBONE\u001b[39;49;00m\n\u001b[32m    689\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfusion_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconcat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfreeze_backbone_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m    695\u001b[39m     \u001b[38;5;66;03m# Train with ultra-stable settings\u001b[39;00m\n\u001b[32m    696\u001b[39m     trained_model, results = train_ultra_stable(\n\u001b[32m    697\u001b[39m         model=model,\n\u001b[32m    698\u001b[39m         train_loader=train_loader,\n\u001b[32m   (...)\u001b[39m\u001b[32m    710\u001b[39m         device=device\n\u001b[32m    711\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 555\u001b[39m, in \u001b[36mcreate_stable_model\u001b[39m\u001b[34m(backbone_name, num_features, fusion_method, dropout, freeze_backbone_epochs, pretrained)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_stable_model\u001b[39m(\n\u001b[32m    533\u001b[39m     backbone_name: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33mefficientnet_b0\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    534\u001b[39m     num_features: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    538\u001b[39m     pretrained: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    539\u001b[39m ) -> UltraStableHousePriceModel:\n\u001b[32m    540\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    541\u001b[39m \u001b[33;03m    Factory function to create stable models\u001b[39;00m\n\u001b[32m    542\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    552\u001b[39m \u001b[33;03m    - 'swin_t' - Unstable for regression\u001b[39;00m\n\u001b[32m    553\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m     model = \u001b[43mUltraStableHousePriceModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackbone_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackbone_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_tabular_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfusion_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfusion_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfreeze_backbone_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfreeze_backbone_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m     \u001b[38;5;66;03m# Freeze backbone initially if requested\u001b[39;00m\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m freeze_backbone_epochs > \u001b[32m0\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: UltraStableHousePriceModel.__init__() got an unexpected keyword argument 'fusion_method'"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# ============================================================================\n",
    "# STAGE 6: ULTRA-STABLE TRAINING FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR, ReduceLROnPlateau\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# ULTRA-STABLE LOSS FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "class SafeHuberLoss(nn.Module):\n",
    "    \"\"\"Huber loss with NaN/Inf protection\"\"\"\n",
    "    def __init__(self, delta=1.0):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # Clamp inputs to prevent extreme values\n",
    "        pred = torch.clamp(pred, min=-20, max=20)\n",
    "        target = torch.clamp(target, min=-20, max=20)\n",
    "        \n",
    "        error = torch.abs(pred - target)\n",
    "        quadratic = torch.min(error, torch.tensor(self.delta, device=error.device))\n",
    "        linear = error - quadratic\n",
    "        loss = torch.mean(0.5 * quadratic**2 + self.delta * linear)\n",
    "        \n",
    "        # Safety check\n",
    "        if not torch.isfinite(loss):\n",
    "            return torch.tensor(1.0, device=pred.device, requires_grad=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "class SafeCombinedLoss(nn.Module):\n",
    "    \"\"\"Combined loss with stability guarantees\"\"\"\n",
    "    def __init__(self, alpha=0.4, beta=0.3, gamma=0.3):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # MSE weight\n",
    "        self.beta = beta    # MAE weight  \n",
    "        self.gamma = gamma  # Huber weight\n",
    "        self.huber = SafeHuberLoss(delta=1.0)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # Clamp to prevent extreme values\n",
    "        pred = torch.clamp(pred, min=-20, max=20)\n",
    "        target = torch.clamp(target, min=-20, max=20)\n",
    "        \n",
    "        # MSE component\n",
    "        mse = torch.mean((pred - target) ** 2)\n",
    "        \n",
    "        # MAE component\n",
    "        mae = torch.mean(torch.abs(pred - target))\n",
    "        \n",
    "        # Huber component\n",
    "        huber = self.huber(pred, target)\n",
    "        \n",
    "        # Combined loss\n",
    "        loss = self.alpha * mse + self.beta * mae + self.gamma * huber\n",
    "        \n",
    "        # Final safety check\n",
    "        if not torch.isfinite(loss):\n",
    "            return torch.tensor(1.0, device=pred.device, requires_grad=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# GRADIENT SAFETY UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def check_model_gradients(model, max_norm=10.0):\n",
    "    \"\"\"\n",
    "    Check model gradients for NaN/Inf and extreme values\n",
    "    Returns: (has_nan, has_inf, max_grad_norm)\n",
    "    \"\"\"\n",
    "    has_nan = False\n",
    "    has_inf = False\n",
    "    max_grad = 0.0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            grad = param.grad\n",
    "            \n",
    "            # Check for NaN\n",
    "            if torch.isnan(grad).any():\n",
    "                has_nan = True\n",
    "                logger.warning(f\"‚ö†Ô∏è  NaN gradient in {name}\")\n",
    "            \n",
    "            # Check for Inf\n",
    "            if torch.isinf(grad).any():\n",
    "                has_inf = True\n",
    "                logger.warning(f\"‚ö†Ô∏è  Inf gradient in {name}\")\n",
    "            \n",
    "            # Check magnitude\n",
    "            grad_norm = grad.norm().item()\n",
    "            max_grad = max(max_grad, grad_norm)\n",
    "            \n",
    "            if grad_norm > max_norm:\n",
    "                logger.warning(f\"‚ö†Ô∏è  Large gradient ({grad_norm:.2f}) in {name}\")\n",
    "    \n",
    "    return has_nan, has_inf, max_grad\n",
    "\n",
    "\n",
    "def sanitize_gradients(model):\n",
    "    \"\"\"Replace NaN/Inf gradients with zeros\"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            param.grad = torch.nan_to_num(\n",
    "                param.grad, \n",
    "                nan=0.0, \n",
    "                posinf=0.0, \n",
    "                neginf=0.0\n",
    "            )\n",
    "\n",
    "\n",
    "def check_model_weights(model):\n",
    "    \"\"\"Check model weights for NaN/Inf\"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if not torch.isfinite(param).all():\n",
    "            logger.error(f\"‚ùå NaN/Inf in weights: {name}\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ULTRA-STABLE TRAINING FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def train_ultra_stable(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader=None,\n",
    "    num_epochs=50,\n",
    "    lr=0.001,  # LOWER default learning rate\n",
    "    loss_type='combined',\n",
    "    optimizer_type='adamw',\n",
    "    scheduler_type='plateau',\n",
    "    gradient_clip_norm=0.5,  # AGGRESSIVE clipping\n",
    "    gradient_accumulation_steps=1,\n",
    "    warmup_epochs=5,  # Longer warmup\n",
    "    early_stopping_patience=15,\n",
    "    save_best_model=True,\n",
    "    checkpoint_dir='./checkpoints',\n",
    "    model_name='model',\n",
    "    device='cuda'\n",
    "):\n",
    "    \"\"\"\n",
    "    Ultra-stable training with maximum gradient safety\n",
    "    \n",
    "    Key Safety Features:\n",
    "    1. Aggressive gradient clipping (0.5 default)\n",
    "    2. NaN/Inf detection at every step\n",
    "    3. Automatic gradient sanitization\n",
    "    4. Weight validation after each epoch\n",
    "    5. Safe loss clamping\n",
    "    6. Conservative learning rates\n",
    "    7. Extended warmup period\n",
    "    8. Automatic recovery from instability\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'\\n{\"=\"*80}')\n",
    "    print(f'üõ°Ô∏è  ULTRA-STABLE TRAINING: {model_name}')\n",
    "    print(f'{\"=\"*80}')\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SETUP\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Loss function with stability\n",
    "    print(f'\\nüéØ Loss Function: {loss_type.upper()}')\n",
    "    if loss_type == 'combined':\n",
    "        criterion = SafeCombinedLoss(alpha=0.4, beta=0.3, gamma=0.3)\n",
    "    elif loss_type == 'huber':\n",
    "        criterion = SafeHuberLoss(delta=1.0)\n",
    "    elif loss_type == 'mse':\n",
    "        criterion = nn.MSELoss()\n",
    "    else:\n",
    "        criterion = SafeCombinedLoss()\n",
    "    \n",
    "    # Optimizer with conservative settings\n",
    "    print(f'‚öôÔ∏è  Optimizer: {optimizer_type.upper()}')\n",
    "    if optimizer_type == 'adamw':\n",
    "        optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=1e-4,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-8  # Stability\n",
    "        )\n",
    "    elif optimizer_type == 'adam':\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=1e-4,\n",
    "            eps=1e-8\n",
    "        )\n",
    "    elif optimizer_type == 'sgd':\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            momentum=0.9,\n",
    "            weight_decay=1e-4,\n",
    "            nesterov=True\n",
    "        )\n",
    "    else:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    print(f'üìà Scheduler: {scheduler_type.upper()}')\n",
    "    if scheduler_type == 'plateau':\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=7,\n",
    "            min_lr=1e-7,\n",
    "            cooldown=3,\n",
    "            verbose=True\n",
    "        )\n",
    "    elif scheduler_type == 'cosine':\n",
    "        scheduler = CosineAnnealingWarmRestarts(\n",
    "            optimizer,\n",
    "            T_0=10,\n",
    "            T_mult=2,\n",
    "            eta_min=1e-7\n",
    "        )\n",
    "    elif scheduler_type == 'onecycle':\n",
    "        total_steps = len(train_loader) * num_epochs\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=lr * 5,  # Conservative multiplier\n",
    "            total_steps=total_steps,\n",
    "            pct_start=0.3,\n",
    "            anneal_strategy='cos'\n",
    "        )\n",
    "    else:\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=7)\n",
    "    \n",
    "    # Mixed precision with safety\n",
    "    use_amp = torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 7\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "    if use_amp:\n",
    "        print(f'‚ö° Mixed Precision: ENABLED')\n",
    "    \n",
    "    # Training configuration\n",
    "    print(f'\\nüìã Training Configuration:')\n",
    "    print(f'   Epochs: {num_epochs}')\n",
    "    print(f'   Learning Rate: {lr}')\n",
    "    print(f'   Gradient Clip: {gradient_clip_norm}')\n",
    "    print(f'   Warmup Epochs: {warmup_epochs}')\n",
    "    print(f'   Accumulation Steps: {gradient_accumulation_steps}')\n",
    "    print(f'   Early Stopping Patience: {early_stopping_patience}')\n",
    "    print(f'   Device: {device}')\n",
    "    \n",
    "    # Training state\n",
    "    history = defaultdict(list)\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_r2 = -float('inf')\n",
    "    best_model_state = None\n",
    "    no_improve_count = 0\n",
    "    nan_inf_count = 0\n",
    "    max_nan_inf_tolerance = 3  # Stop if too many NaN/Inf episodes\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create checkpoint directory\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MAIN TRAINING LOOP\n",
    "    # ========================================================================\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Check model weights before epoch\n",
    "        if not check_model_weights(model):\n",
    "            logger.error(\"‚ùå Model weights corrupted! Stopping training.\")\n",
    "            break\n",
    "        \n",
    "        # ====================================================================\n",
    "        # WARMUP LEARNING RATE\n",
    "        # ====================================================================\n",
    "        if epoch < warmup_epochs:\n",
    "            warmup_factor = (epoch + 1) / warmup_epochs\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * warmup_factor\n",
    "            logger.info(f\"Warmup LR: {lr * warmup_factor:.2e}\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # TRAINING PHASE\n",
    "        # ====================================================================\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_preds_list = []\n",
    "        train_targets_list = []\n",
    "        batch_nan_count = 0\n",
    "        \n",
    "        train_pbar = tqdm(\n",
    "            train_loader,\n",
    "            desc=f'Epoch {epoch+1}/{num_epochs} [Train]',\n",
    "            ncols=120\n",
    "        )\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for batch_idx, (images, features, prices) in enumerate(train_pbar):\n",
    "            try:\n",
    "                # Move to device\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                features = features.to(device, non_blocking=True)\n",
    "                prices = prices.to(device, non_blocking=True)\n",
    "                \n",
    "                # Safety check on inputs\n",
    "                if not torch.isfinite(images).all():\n",
    "                    logger.warning(f\"‚ö†Ô∏è  NaN/Inf in images batch {batch_idx}\")\n",
    "                    images = torch.nan_to_num(images, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "                \n",
    "                if not torch.isfinite(features).all():\n",
    "                    logger.warning(f\"‚ö†Ô∏è  NaN/Inf in features batch {batch_idx}\")\n",
    "                    features = torch.nan_to_num(features, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "                \n",
    "                # Forward pass with mixed precision\n",
    "                with autocast(enabled=use_amp):\n",
    "                    outputs = model(images, features)\n",
    "                    \n",
    "                    # Check outputs\n",
    "                    if not torch.isfinite(outputs).all():\n",
    "                        logger.warning(f\"‚ö†Ô∏è  NaN/Inf in model outputs batch {batch_idx}!\")\n",
    "                        outputs = torch.nan_to_num(outputs, nan=0.0, posinf=10.0, neginf=-10.0)\n",
    "                        outputs = torch.clamp(outputs, min=-15.0, max=15.0)\n",
    "                        batch_nan_count += 1\n",
    "                    \n",
    "                    # Compute loss\n",
    "                    loss = criterion(outputs, prices)\n",
    "                    loss = loss / gradient_accumulation_steps\n",
    "                    \n",
    "                    # Check loss\n",
    "                    if not torch.isfinite(loss):\n",
    "                        logger.warning(f\"‚ö†Ô∏è  NaN/Inf loss batch {batch_idx}! Skipping...\")\n",
    "                        batch_nan_count += 1\n",
    "                        continue\n",
    "                \n",
    "                # Backward pass\n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                # Gradient accumulation\n",
    "                if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "                    # Check gradients\n",
    "                    has_nan, has_inf, max_grad = check_model_gradients(model)\n",
    "                    \n",
    "                    if has_nan or has_inf:\n",
    "                        logger.warning(f\"‚ö†Ô∏è  NaN/Inf gradients detected! Sanitizing...\")\n",
    "                        sanitize_gradients(model)\n",
    "                        batch_nan_count += 1\n",
    "                    \n",
    "                    # Unscale gradients\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    \n",
    "                    # AGGRESSIVE gradient clipping\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        model.parameters(),\n",
    "                        max_norm=gradient_clip_norm\n",
    "                    )\n",
    "                    \n",
    "                    # Optimizer step\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # Update OneCycle scheduler\n",
    "                    if scheduler_type == 'onecycle':\n",
    "                        scheduler.step()\n",
    "                \n",
    "                # Accumulate loss and predictions\n",
    "                train_loss += loss.item() * gradient_accumulation_steps\n",
    "                train_preds_list.extend(outputs.detach().cpu().numpy())\n",
    "                train_targets_list.extend(prices.cpu().numpy())\n",
    "                \n",
    "                # Update progress bar\n",
    "                if (batch_idx + 1) % 5 == 0:\n",
    "                    current_lr = optimizer.param_groups[0]['lr']\n",
    "                    train_pbar.set_postfix({\n",
    "                        'loss': f'{loss.item() * gradient_accumulation_steps:.4f}',\n",
    "                        'lr': f'{current_lr:.2e}',\n",
    "                        'nan': batch_nan_count\n",
    "                    })\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                logger.error(f\"‚ùå Runtime error in batch {batch_idx}: {e}\")\n",
    "                if \"out of memory\" in str(e):\n",
    "                    logger.error(\"üí• GPU OOM! Clearing cache...\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                continue\n",
    "        \n",
    "        # Check for excessive NaN/Inf in epoch\n",
    "        if batch_nan_count > len(train_loader) * 0.1:  # >10% batches corrupted\n",
    "            logger.error(f\"‚ùå Too many NaN/Inf batches ({batch_nan_count})! Epoch unstable.\")\n",
    "            nan_inf_count += 1\n",
    "            if nan_inf_count >= max_nan_inf_tolerance:\n",
    "                logger.error(\"üí• Training unstable! Stopping...\")\n",
    "                break\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # CALCULATE TRAINING METRICS (SAFELY)\n",
    "        # ====================================================================\n",
    "        train_preds_norm = np.array(train_preds_list).reshape(-1, 1)\n",
    "        train_targets_norm = np.array(train_targets_list).reshape(-1, 1)\n",
    "        \n",
    "        # Safety checks\n",
    "        if not np.isfinite(train_preds_norm).all():\n",
    "            logger.warning('‚ö†Ô∏è  NaN/Inf in training predictions!')\n",
    "            train_preds_norm = np.nan_to_num(train_preds_norm, nan=0.0, posinf=5.0, neginf=-5.0)\n",
    "            train_preds_norm = np.clip(train_preds_norm, -15, 15)\n",
    "        \n",
    "        try:\n",
    "            # Denormalize\n",
    "            train_preds_denorm = train_loader.dataset.price_scaler.inverse_transform(\n",
    "                train_preds_norm\n",
    "            ).flatten()\n",
    "            train_targets_denorm = train_loader.dataset.price_scaler.inverse_transform(\n",
    "                train_targets_norm\n",
    "            ).flatten()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_r2 = r2_score(train_targets_denorm, train_preds_denorm)\n",
    "            train_rmse = np.sqrt(mean_squared_error(train_targets_denorm, train_preds_denorm))\n",
    "            train_mae = mean_absolute_error(train_targets_denorm, train_preds_denorm)\n",
    "            \n",
    "            # Clamp unrealistic metrics\n",
    "            train_r2 = max(-10.0, min(1.0, train_r2))\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error calculating training metrics: {e}\")\n",
    "            train_r2 = 0.0\n",
    "            train_rmse = float('inf')\n",
    "            train_mae = float('inf')\n",
    "        \n",
    "        # ====================================================================\n",
    "        # VALIDATION PHASE\n",
    "        # ====================================================================\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds_list = []\n",
    "        val_targets_list = []\n",
    "        \n",
    "        val_pbar = tqdm(\n",
    "            val_loader,\n",
    "            desc=f'Epoch {epoch+1}/{num_epochs} [Val]',\n",
    "            leave=False,\n",
    "            ncols=120\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, features, prices in val_pbar:\n",
    "                try:\n",
    "                    images = images.to(device, non_blocking=True)\n",
    "                    features = features.to(device, non_blocking=True)\n",
    "                    prices = prices.to(device, non_blocking=True)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    with autocast(enabled=use_amp):\n",
    "                        outputs = model(images, features)\n",
    "                        \n",
    "                        # Safety check\n",
    "                        if not torch.isfinite(outputs).all():\n",
    "                            outputs = torch.nan_to_num(outputs, nan=0.0, posinf=10.0, neginf=-10.0)\n",
    "                            outputs = torch.clamp(outputs, min=-15.0, max=15.0)\n",
    "                        \n",
    "                        loss = criterion(outputs, prices)\n",
    "                        \n",
    "                        if not torch.isfinite(loss):\n",
    "                            logger.warning(\"‚ö†Ô∏è  NaN/Inf in validation loss!\")\n",
    "                            continue\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    val_preds_list.extend(outputs.cpu().numpy())\n",
    "                    val_targets_list.extend(prices.cpu().numpy())\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"‚ùå Validation error: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else float('inf')\n",
    "        \n",
    "        # ====================================================================\n",
    "        # CALCULATE VALIDATION METRICS (SAFELY)\n",
    "        # ====================================================================\n",
    "        val_preds_norm = np.array(val_preds_list).reshape(-1, 1)\n",
    "        val_targets_norm = np.array(val_targets_list).reshape(-1, 1)\n",
    "        \n",
    "        if not np.isfinite(val_preds_norm).all():\n",
    "            logger.warning('‚ö†Ô∏è  NaN/Inf in validation predictions!')\n",
    "            val_preds_norm = np.nan_to_num(val_preds_norm, nan=0.0, posinf=5.0, neginf=-5.0)\n",
    "            val_preds_norm = np.clip(val_preds_norm, -15, 15)\n",
    "        \n",
    "        try:\n",
    "            val_preds_denorm = val_loader.dataset.price_scaler.inverse_transform(\n",
    "                val_preds_norm\n",
    "            ).flatten()\n",
    "            val_targets_denorm = val_loader.dataset.price_scaler.inverse_transform(\n",
    "                val_targets_norm\n",
    "            ).flatten()\n",
    "            \n",
    "            val_r2 = r2_score(val_targets_denorm, val_preds_denorm)\n",
    "            val_rmse = np.sqrt(mean_squared_error(val_targets_denorm, val_preds_denorm))\n",
    "            val_mae = mean_absolute_error(val_targets_denorm, val_preds_denorm)\n",
    "            \n",
    "            # Clamp metrics\n",
    "            val_r2 = max(-10.0, min(1.0, val_r2))\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error calculating validation metrics: {e}\")\n",
    "            val_r2 = 0.0\n",
    "            val_rmse = float('inf')\n",
    "            val_mae = float('inf')\n",
    "        \n",
    "        # ====================================================================\n",
    "        # UPDATE SCHEDULER\n",
    "        # ====================================================================\n",
    "        if scheduler_type == 'plateau':\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif scheduler_type == 'cosine':\n",
    "            scheduler.step()\n",
    "        \n",
    "        # ====================================================================\n",
    "        # SAVE HISTORY\n",
    "        # ====================================================================\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_r2'].append(train_r2)\n",
    "        history['train_rmse'].append(train_rmse)\n",
    "        history['train_mae'].append(train_mae)\n",
    "        \n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_r2'].append(val_r2)\n",
    "        history['val_rmse'].append(val_rmse)\n",
    "        history['val_mae'].append(val_mae)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        history['epoch_time'].append(epoch_time)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # LOGGING\n",
    "        # ====================================================================\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        is_best = (avg_val_loss < best_val_loss and np.isfinite(avg_val_loss))\n",
    "        \n",
    "        print(f'\\n{\"=\"*80}')\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} Summary ({epoch_time:.2f}s)')\n",
    "        print(f'{\"=\"*80}')\n",
    "        print(f'üìâ Train Loss: {avg_train_loss:.6f} | R¬≤: {train_r2:.4f} | RMSE: ${train_rmse:,.0f}')\n",
    "        print(f'üìä Val Loss: {avg_val_loss:.6f} | R¬≤: {val_r2:.4f} | RMSE: ${val_rmse:,.0f}')\n",
    "        print(f'üéØ Val MAE: ${val_mae:,.0f}')\n",
    "        print(f'üîß Learning Rate: {current_lr:.2e}')\n",
    "        print(f'‚ö†Ô∏è  NaN/Inf Batches: {batch_nan_count}')\n",
    "        \n",
    "        if is_best:\n",
    "            print(f'‚≠ê NEW BEST MODEL!')\n",
    "        \n",
    "        # ====================================================================\n",
    "        # MODEL CHECKPOINTING\n",
    "        # ====================================================================\n",
    "        if is_best:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_val_r2 = val_r2\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            no_improve_count = 0\n",
    "            \n",
    "            if save_best_model:\n",
    "                checkpoint_path = os.path.join(checkpoint_dir, f'{model_name}_best.pth')\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_loss': best_val_loss,\n",
    "                    'val_r2': best_val_r2,\n",
    "                    'history': dict(history)\n",
    "                }, checkpoint_path)\n",
    "                print(f'üíæ Checkpoint saved: {checkpoint_path}')\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            print(f'‚è≥ No improvement for {no_improve_count}/{early_stopping_patience} epochs')\n",
    "            \n",
    "            if no_improve_count >= early_stopping_patience:\n",
    "                print(f'\\nüõë Early stopping at epoch {epoch+1}')\n",
    "                break\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LOAD BEST MODEL\n",
    "    # ========================================================================\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print('\\n‚úÖ Best model loaded')\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FINAL TEST EVALUATION\n",
    "    # ========================================================================\n",
    "    if test_loader is not None:\n",
    "        print('\\n' + '='*80)\n",
    "        print('üß™ FINAL TEST EVALUATION')\n",
    "        print('='*80)\n",
    "        \n",
    "        model.eval()\n",
    "        test_preds_list = []\n",
    "        test_targets_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, features, prices in tqdm(test_loader, desc='Testing', ncols=120):\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                features = features.to(device, non_blocking=True)\n",
    "                prices = prices.to(device, non_blocking=True)\n",
    "                \n",
    "                outputs = model(images, features)\n",
    "                \n",
    "                # Safety\n",
    "                if not torch.isfinite(outputs).all():\n",
    "                    outputs = torch.nan_to_num(outputs, nan=0.0, posinf=10.0, neginf=-10.0)\n",
    "                \n",
    "                test_preds_list.extend(outputs.cpu().numpy())\n",
    "                test_targets_list.extend(prices.cpu().numpy())\n",
    "        \n",
    "        # Calculate test metrics\n",
    "        test_preds_norm = np.array(test_preds_list).reshape(-1, 1)\n",
    "        test_targets_norm = np.array(test_targets_list).reshape(-1, 1)\n",
    "        \n",
    "        test_preds = test_loader.dataset.price_scaler.inverse_transform(test_preds_norm).flatten()\n",
    "        test_targets = test_loader.dataset.price_scaler.inverse_transform(test_targets_norm).flatten()\n",
    "        \n",
    "        test_r2 = r2_score(test_targets, test_preds)\n",
    "        test_rmse = np.sqrt(mean_squared_error(test_targets, test_preds))\n",
    "        test_mae = mean_absolute_error(test_targets, test_preds)\n",
    "        \n",
    "        print(f'\\nüìä TEST RESULTS: {model_name}')\n",
    "        print(f'{\"=\"*80}')\n",
    "        print(f'  üéØ R¬≤ Score:      {test_r2:.4f}')\n",
    "        print(f'  üìâ RMSE:         ${test_rmse:,.0f}')\n",
    "        print(f'  üìè MAE:          ${test_mae:,.0f}')\n",
    "        print(f'  ‚è±Ô∏è  Training Time: {training_time/60:.2f} min')\n",
    "        print(f'{\"=\"*80}')\n",
    "    else:\n",
    "        test_r2 = test_rmse = test_mae = None\n",
    "    \n",
    "    # ========================================================================\n",
    "    # COMPILE RESULTS\n",
    "    # ========================================================================\n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'test_r2': test_r2,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'best_val_r2': best_val_r2,\n",
    "        'training_time': training_time,\n",
    "        'total_epochs': len(history['train_loss']),\n",
    "        'history': dict(history),\n",
    "        'nan_inf_episodes': nan_inf_count\n",
    "    }\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create stable model\n",
    "    model = create_stable_model(\n",
    "        backbone_name='efficientnet_b0',  # SAFE BACKBONE\n",
    "        num_features=5,\n",
    "        fusion_method='concat',\n",
    "        dropout=0.3,\n",
    "        freeze_backbone_epochs=5\n",
    "    ).to(device)\n",
    "    \n",
    "    # Train with ultra-stable settings\n",
    "    trained_model, results = train_ultra_stable(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        num_epochs=50,\n",
    "        lr=0.001,  # Conservative LR\n",
    "        loss_type='combined',\n",
    "        optimizer_type='adamw',\n",
    "        scheduler_type='plateau',\n",
    "        gradient_clip_norm=0.5,  # Aggressive clipping\n",
    "        warmup_epochs=5,\n",
    "        early_stopping_patience=15,\n",
    "        model_name='efficientnet_b0_stable',\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training complete!\")\n",
    "    print(f\"Final R¬≤: {results['test_r2']:.4f}\")\n",
    "    print(f\"Final RMSE: ${results['test_rmse']:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b14066a",
   "metadata": {},
   "source": [
    "Stage 7: COMPLETE PRE-TRAINING TEST & 21 MODEL ENSEMBLE PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e45085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Session Directory: model_outputs\\20251126_030804\n",
      "\n",
      "================================================================================\n",
      "üöÄ Starting Ensemble Training Session\n",
      "================================================================================\n",
      "üìä Total models to train: 21\n",
      "üìÅ Session ID: 20251126_030804\n",
      "üíæ Output directory: model_outputs\\20251126_030804\n",
      "üñ•Ô∏è  Device: cuda\n",
      "================================================================================\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [1/21] üèóÔ∏è  Training: ResNet50_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for ResNet50_MultiModal:\n",
      "   lr: 0.001\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training ResNet50_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: ResNet50_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training ResNet50_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 1/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 1\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [2/21] üèóÔ∏è  Training: ResNet101_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for ResNet101_MultiModal:\n",
      "   lr: 0.001\n",
      "   num_epochs: 50\n",
      "   loss_type: mae\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training ResNet101_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: ResNet101_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training ResNet101_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 2/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 2\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [3/21] üèóÔ∏è  Training: EfficientNetB3_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for EfficientNetB3_MultiModal:\n",
      "   lr: 0.002\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 2\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training EfficientNetB3_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: EfficientNetB3_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training EfficientNetB3_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 3/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 3\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [4/21] üèóÔ∏è  Training: EfficientNetB5_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for EfficientNetB5_MultiModal:\n",
      "   lr: 0.002\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 2\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training EfficientNetB5_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: EfficientNetB5_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training EfficientNetB5_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 4/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 4\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [5/21] üèóÔ∏è  Training: DenseNet121_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for DenseNet121_MultiModal:\n",
      "   lr: 0.003\n",
      "   num_epochs: 45\n",
      "   loss_type: combined\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: False\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training DenseNet121_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: DenseNet121_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training DenseNet121_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 5/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 5\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [6/21] üèóÔ∏è  Training: DenseNet169_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for DenseNet169_MultiModal:\n",
      "   lr: 0.003\n",
      "   num_epochs: 45\n",
      "   loss_type: combined\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: False\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training DenseNet169_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: DenseNet169_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training DenseNet169_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 6/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 6\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [7/21] üèóÔ∏è  Training: VGG16_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for VGG16_MultiModal:\n",
      "   lr: 0.005\n",
      "   num_epochs: 40\n",
      "   loss_type: huber\n",
      "   optimizer_type: sgd\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training VGG16_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: VGG16_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training VGG16_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 7/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 7\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [8/21] üèóÔ∏è  Training: VGG19_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for VGG19_MultiModal:\n",
      "   lr: 0.005\n",
      "   num_epochs: 40\n",
      "   loss_type: mse\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training VGG19_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: VGG19_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training VGG19_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 8/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 8\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [9/21] üèóÔ∏è  Training: MobileNetV2_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for MobileNetV2_MultiModal:\n",
      "   lr: 0.004\n",
      "   num_epochs: 45\n",
      "   loss_type: mae\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: onecycle\n",
      "   use_swa: False\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training MobileNetV2_MultiModal with ROBUST Configuration\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: MobileNetV2_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training MobileNetV2_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 9/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 9\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [10/21] üèóÔ∏è  Training: MobileNetV3_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for MobileNetV3_MultiModal:\n",
      "   lr: 0.004\n",
      "   num_epochs: 45\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: onecycle\n",
      "   use_swa: False\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training MobileNetV3_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: MobileNetV3_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training MobileNetV3_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 10/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 10\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [11/21] üèóÔ∏è  Training: ViT_B16_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for ViT_B16_MultiModal:\n",
      "   lr: 0.0001\n",
      "   num_epochs: 40\n",
      "   loss_type: mae\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: False\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 4\n",
      "   warmup_epochs: 10\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training ViT_B16_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: ViT_B16_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training ViT_B16_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 11/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 11\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [12/21] üèóÔ∏è  Training: ViT_B32_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for ViT_B32_MultiModal:\n",
      "   lr: 0.0001\n",
      "   num_epochs: 40\n",
      "   loss_type: mae\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: False\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 4\n",
      "   warmup_epochs: 10\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training ViT_B32_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: ViT_B32_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training ViT_B32_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 12/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 12\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [13/21] üèóÔ∏è  Training: Inception_V3_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for Inception_V3_MultiModal:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training Inception_V3_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: Inception_V3_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training Inception_V3_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 13/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 13\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [14/21] üèóÔ∏è  Training: Xception_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for Xception_MultiModal:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: combined\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training Xception_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: Xception_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training Xception_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 14/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 14\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [15/21] üèóÔ∏è  Training: NASNet_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for NASNet_MultiModal:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: combined\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training NASNet_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: NASNet_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training NASNet_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 15/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 15\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [16/21] üèóÔ∏è  Training: SEResNet50_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for SEResNet50_MultiModal:\n",
      "   lr: 0.001\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training SEResNet50_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: SEResNet50_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training SEResNet50_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 16/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 16\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [17/21] üèóÔ∏è  Training: RegNetY_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for RegNetY_MultiModal:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: combined\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training RegNetY_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: RegNetY_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training RegNetY_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 17/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 17\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [18/21] üèóÔ∏è  Training: ConvNeXt_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for ConvNeXt_MultiModal:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: combined\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training ConvNeXt_MultiModal with ROBUST Configuration\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: ConvNeXt_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training ConvNeXt_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 18/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 18\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [19/21] üèóÔ∏è  Training: Swin_Transformer_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for Swin_Transformer_MultiModal:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training Swin_Transformer_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: Swin_Transformer_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training Swin_Transformer_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 19/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 19\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [20/21] üèóÔ∏è  Training: EfficientNetV2_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for EfficientNetV2_MultiModal:\n",
      "   lr: 0.002\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 2\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training EfficientNetV2_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: EfficientNetV2_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training EfficientNetV2_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 20/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 20\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [21/21] üèóÔ∏è  Training: MaxViT_MultiModal\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for MaxViT_MultiModal:\n",
      "   lr: 0.0001\n",
      "   num_epochs: 40\n",
      "   loss_type: mae\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: False\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 4\n",
      "   warmup_epochs: 10\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training MaxViT_MultiModal with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: MaxViT_MultiModal...\n",
      "‚ùå Error creating model: name 'get_model' is not defined\n",
      "\n",
      "‚ùå Error training MaxViT_MultiModal: name 'get_model' is not defined\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 21/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 21\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üéâ Ensemble Training Completed!\n",
      "================================================================================\n",
      "‚úÖ Successfully trained: 0/21 models\n",
      "‚ùå Failed: 21/21 models\n",
      "‚è±Ô∏è  Total training time: 0.01 minutes (0.00 hours)\n",
      "üìÅ All outputs saved to: model_outputs\\20251126_030804\n",
      "================================================================================\n",
      "\n",
      "üìä Generating training summary and visualizations...\n",
      "\n",
      "‚ö†Ô∏è  No models trained successfully!\n",
      "\n",
      "üéâ All done! Check the output directory for results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\2782451258.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20916\\475955486.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^\n",
      "NameError: name 'get_model' is not defined. Did you mean: 'test_models'?\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPREHENSIVE PRE-TRAINING TEST SUITE\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "class PreTrainingValidator:\n",
    "    \"\"\"\n",
    "    Comprehensive validation before training 21 models\n",
    "    Tests: Data, Models, Training Functions, GPU, Stability\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, train_loader, val_loader, test_loader, device):\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.test_results = defaultdict(list)\n",
    "        self.passed_tests = 0\n",
    "        self.total_tests = 0\n",
    "        \n",
    "    def run_all_tests(self):\n",
    "        \"\"\"Run complete test suite\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üß™ COMPREHENSIVE PRE-TRAINING VALIDATION\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # Run all test categories\n",
    "        self.test_environment()\n",
    "        self.test_data_loaders()\n",
    "        self.test_all_models()\n",
    "        self.test_training_functions()\n",
    "        self.test_loss_functions()\n",
    "        self.test_stability()\n",
    "        \n",
    "        # Print final summary\n",
    "        self.print_summary()\n",
    "        \n",
    "        return self.passed_tests == self.total_tests\n",
    "    \n",
    "    def _run_test(self, test_name, test_func):\n",
    "        \"\"\"Helper to run individual test with error handling\"\"\"\n",
    "        self.total_tests += 1\n",
    "        try:\n",
    "            result = test_func()\n",
    "            if result:\n",
    "                self.passed_tests += 1\n",
    "                print(f\"   ‚úÖ {test_name}\")\n",
    "                self.test_results[test_name] = \"PASS\"\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"   ‚ùå {test_name}: FAILED\")\n",
    "                self.test_results[test_name] = \"FAIL\"\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå {test_name}: ERROR - {str(e)[:60]}\")\n",
    "            self.test_results[test_name] = f\"ERROR: {str(e)[:60]}\"\n",
    "            return False\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TEST CATEGORY 1: ENVIRONMENT\n",
    "    # ========================================================================\n",
    "    \n",
    "    def test_environment(self):\n",
    "        \"\"\"Test computational environment\"\"\"\n",
    "        \n",
    "        print(\"1Ô∏è‚É£  ENVIRONMENT TESTS\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        def test_cuda():\n",
    "            if self.device.type == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "                memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "                return memory > 4  # At least 4GB GPU\n",
    "            return True  # CPU is ok\n",
    "        \n",
    "        def test_pytorch_version():\n",
    "            version = torch.__version__\n",
    "            major, minor = int(version.split('.')[0]), int(version.split('.')[1])\n",
    "            return major >= 1 and minor >= 10\n",
    "        \n",
    "        def test_device_available():\n",
    "            return self.device is not None\n",
    "        \n",
    "        def test_amp_support():\n",
    "            if self.device.type == 'cuda':\n",
    "                return torch.cuda.get_device_capability()[0] >= 7\n",
    "            return True\n",
    "        \n",
    "        self._run_test(\"CUDA/Device Available\", test_device_available)\n",
    "        self._run_test(\"PyTorch Version (>=1.10)\", test_pytorch_version)\n",
    "        self._run_test(\"GPU Memory (>4GB)\", test_cuda)\n",
    "        self._run_test(\"Mixed Precision Support\", test_amp_support)\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TEST CATEGORY 2: DATA LOADERS\n",
    "    # ========================================================================\n",
    "    \n",
    "    def test_data_loaders(self):\n",
    "        \"\"\"Test all data loaders\"\"\"\n",
    "        \n",
    "        print(\"2Ô∏è‚É£  DATA LOADER TESTS\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        def test_train_loader():\n",
    "            batch = next(iter(self.train_loader))\n",
    "            images, features, prices = batch\n",
    "            return (len(batch) == 3 and \n",
    "                    images.shape[0] > 0 and \n",
    "                    features.shape[0] > 0 and\n",
    "                    prices.shape[0] > 0)\n",
    "        \n",
    "        def test_val_loader():\n",
    "            batch = next(iter(self.val_loader))\n",
    "            images, features, prices = batch\n",
    "            return len(batch) == 3 and images.shape[0] > 0\n",
    "        \n",
    "        def test_test_loader():\n",
    "            batch = next(iter(self.test_loader))\n",
    "            images, features, prices = batch\n",
    "            return len(batch) == 3 and images.shape[0] > 0\n",
    "        \n",
    "        def test_data_shapes():\n",
    "            images, features, prices = next(iter(self.train_loader))\n",
    "            return (len(images.shape) == 4 and  # (B, C, H, W)\n",
    "                    images.shape[1] == 3 and  # 3 channels\n",
    "                    len(features.shape) == 2 and  # (B, F)\n",
    "                    len(prices.shape) == 1)  # (B,)\n",
    "        \n",
    "        def test_data_ranges():\n",
    "            images, features, prices = next(iter(self.train_loader))\n",
    "            return (images.min() >= 0 and images.max() <= 1 and  # Normalized images\n",
    "                    torch.isfinite(features).all() and\n",
    "                    torch.isfinite(prices).all())\n",
    "        \n",
    "        def test_no_nan_inf():\n",
    "            images, features, prices = next(iter(self.train_loader))\n",
    "            return (not torch.isnan(images).any() and\n",
    "                    not torch.isnan(features).any() and\n",
    "                    not torch.isnan(prices).any() and\n",
    "                    not torch.isinf(images).any() and\n",
    "                    not torch.isinf(features).any() and\n",
    "                    not torch.isinf(prices).any())\n",
    "        \n",
    "        def test_batch_consistency():\n",
    "            batch1 = next(iter(self.train_loader))\n",
    "            batch2 = next(iter(self.train_loader))\n",
    "            return batch1[0].shape == batch2[0].shape\n",
    "        \n",
    "        def test_dataset_sizes():\n",
    "            return (len(self.train_loader.dataset) >= 100 and\n",
    "                    len(self.val_loader.dataset) >= 20 and\n",
    "                    len(self.test_loader.dataset) >= 20)\n",
    "        \n",
    "        self._run_test(\"Train Loader Functional\", test_train_loader)\n",
    "        self._run_test(\"Validation Loader Functional\", test_val_loader)\n",
    "        self._run_test(\"Test Loader Functional\", test_test_loader)\n",
    "        self._run_test(\"Data Shapes Correct\", test_data_shapes)\n",
    "        self._run_test(\"Data Ranges Valid\", test_data_ranges)\n",
    "        self._run_test(\"No NaN/Inf in Data\", test_no_nan_inf)\n",
    "        self._run_test(\"Batch Consistency\", test_batch_consistency)\n",
    "        self._run_test(\"Dataset Sizes Adequate\", test_dataset_sizes)\n",
    "        \n",
    "        # Print data info\n",
    "        images, features, prices = next(iter(self.train_loader))\n",
    "        print(f\"\\n   üìä Data Info:\")\n",
    "        print(f\"      Images: {images.shape}\")\n",
    "        print(f\"      Features: {features.shape} (num_features={features.shape[1]})\")\n",
    "        print(f\"      Prices: {prices.shape}\")\n",
    "        print(f\"      Train samples: {len(self.train_loader.dataset)}\")\n",
    "        print(f\"      Val samples: {len(self.val_loader.dataset)}\")\n",
    "        print(f\"      Test samples: {len(self.test_loader.dataset)}\")\n",
    "        print()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TEST CATEGORY 3: MODEL ARCHITECTURES\n",
    "    # ========================================================================\n",
    "    \n",
    "    def test_all_models(self):\n",
    "        \"\"\"Test all 21 model architectures\"\"\"\n",
    "        \n",
    "        print(\"3Ô∏è‚É£  MODEL ARCHITECTURE TESTS (21 MODELS)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Get number of features from data\n",
    "        sample_batch = next(iter(self.train_loader))\n",
    "        num_features = sample_batch[1].shape[1]\n",
    "        \n",
    "        # Define all 21+ models to test (SAFE MODELS ONLY)\n",
    "        test_models = [\n",
    "            # EfficientNet Family (5 models)\n",
    "            'efficientnet_b0',\n",
    "            'efficientnet_b1', \n",
    "            'efficientnet_b2',\n",
    "            'efficientnet_b3',\n",
    "            'efficientnet_b4',\n",
    "            \n",
    "            # ResNet Family (4 models)\n",
    "            'resnet50',\n",
    "            'resnet101',\n",
    "            'resnet152',\n",
    "            'wide_resnet50_2',\n",
    "            \n",
    "            # ConvNeXt Family (3 models)\n",
    "            'convnext_tiny',\n",
    "            'convnext_small',\n",
    "            'convnext_base',\n",
    "            \n",
    "            # DenseNet Family (2 models)\n",
    "            'densenet121',\n",
    "            'densenet169',\n",
    "            \n",
    "            # MobileNet Family (2 models)\n",
    "            'mobilenet_v2',\n",
    "            'mobilenet_v3_large',\n",
    "            \n",
    "            # Others (5 models)\n",
    "            'regnet_y_400mf',\n",
    "            'regnet_y_800mf',\n",
    "            'regnet_y_1_6gf',\n",
    "            'shufflenet_v2_x1_0',\n",
    "            'mnasnet1_0'\n",
    "        ]\n",
    "        \n",
    "        successful_models = []\n",
    "        failed_models = []\n",
    "        \n",
    "        for model_name in test_models:\n",
    "            try:\n",
    "                # Create model\n",
    "                model = create_stable_model(\n",
    "                    backbone_name=model_name,\n",
    "                    num_features=num_features,\n",
    "                    fusion_method='concat',\n",
    "                    dropout=0.3,\n",
    "                    pretrained=True\n",
    "                )\n",
    "                model = model.to(self.device)\n",
    "                model.eval()\n",
    "                \n",
    "                # Test forward pass\n",
    "                with torch.no_grad():\n",
    "                    dummy_images = torch.randn(2, 3, 224, 224).to(self.device)\n",
    "                    dummy_features = torch.randn(2, num_features).to(self.device)\n",
    "                    output = model(dummy_images, dummy_features)\n",
    "                \n",
    "                # Check output validity\n",
    "                if (torch.isfinite(output).all() and \n",
    "                    output.shape[0] == 2 and\n",
    "                    len(output.shape) == 1):\n",
    "                    print(f\"   ‚úÖ {model_name:30s} (params: {sum(p.numel() for p in model.parameters()):,})\")\n",
    "                    successful_models.append(model_name)\n",
    "                    self.passed_tests += 1\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è  {model_name:30s} - Invalid output\")\n",
    "                    failed_models.append(model_name)\n",
    "                \n",
    "                self.total_tests += 1\n",
    "                \n",
    "                # Clean up memory\n",
    "                del model\n",
    "                torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå {model_name:30s} - {str(e)[:40]}\")\n",
    "                failed_models.append(model_name)\n",
    "                self.total_tests += 1\n",
    "        \n",
    "        print(f\"\\n   üìä Model Test Summary:\")\n",
    "        print(f\"      ‚úÖ Passed: {len(successful_models)}/{len(test_models)}\")\n",
    "        print(f\"      ‚ùå Failed: {len(failed_models)}/{len(test_models)}\")\n",
    "        \n",
    "        if len(successful_models) >= 21:\n",
    "            print(f\"      üéâ {len(successful_models)} models available - EXCELLENT!\")\n",
    "        elif len(successful_models) >= 15:\n",
    "            print(f\"      ‚úÖ {len(successful_models)} models available - GOOD\")\n",
    "        else:\n",
    "            print(f\"      ‚ö†Ô∏è  Only {len(successful_models)} models available - NEEDS ATTENTION\")\n",
    "        \n",
    "        print()\n",
    "        return successful_models\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TEST CATEGORY 4: TRAINING FUNCTIONS\n",
    "    # ========================================================================\n",
    "    \n",
    "    def test_training_functions(self):\n",
    "        \"\"\"Test training pipeline components\"\"\"\n",
    "        \n",
    "        print(\"4Ô∏è‚É£  TRAINING FUNCTION TESTS\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        def test_loss_functions_exist():\n",
    "            try:\n",
    "                loss1 = SafeCombinedLoss()\n",
    "                loss2 = SafeHuberLoss()\n",
    "                return True\n",
    "            except:\n",
    "                return False\n",
    "        \n",
    "        def test_optimizer_creation():\n",
    "            try:\n",
    "                model = create_stable_model('efficientnet_b0', num_features=5)\n",
    "                opt = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "                return opt is not None\n",
    "            except:\n",
    "                return False\n",
    "        \n",
    "        def test_training_loop_exists():\n",
    "            return callable(train_ultra_stable)\n",
    "        \n",
    "        def test_ensemble_trainer_exists():\n",
    "            try:\n",
    "                trainer = EnsembleTrainer()\n",
    "                return trainer is not None\n",
    "            except:\n",
    "                return False\n",
    "        \n",
    "        def test_gradient_clipping():\n",
    "            try:\n",
    "                model = create_stable_model('efficientnet_b0', num_features=5)\n",
    "                model = model.to(self.device)\n",
    "                \n",
    "                # Create dummy batch\n",
    "                images = torch.randn(2, 3, 224, 224, requires_grad=True).to(self.device)\n",
    "                features = torch.randn(2, 5, requires_grad=True).to(self.device)\n",
    "                \n",
    "                output = model(images, features)\n",
    "                loss = output.mean()\n",
    "                loss.backward()\n",
    "                \n",
    "                # Test gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                return True\n",
    "            except:\n",
    "                return False\n",
    "        \n",
    "        self._run_test(\"Loss Functions Available\", test_loss_functions_exist)\n",
    "        self._run_test(\"Optimizer Creation\", test_optimizer_creation)\n",
    "        self._run_test(\"Training Loop Available\", test_training_loop_exists)\n",
    "        self._run_test(\"Ensemble Trainer Available\", test_ensemble_trainer_exists)\n",
    "        self._run_test(\"Gradient Clipping Works\", test_gradient_clipping)\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TEST CATEGORY 5: LOSS FUNCTIONS\n",
    "    # ========================================================================\n",
    "    \n",
    "    def test_loss_functions(self):\n",
    "        \"\"\"Test all loss functions for stability\"\"\"\n",
    "        \n",
    "        print(\"5Ô∏è‚É£  LOSS FUNCTION TESTS\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Test data\n",
    "        pred = torch.randn(10).to(self.device)\n",
    "        target = torch.randn(10).to(self.device)\n",
    "        \n",
    "        def test_mse_loss():\n",
    "            criterion = nn.MSELoss()\n",
    "            loss = criterion(pred, target)\n",
    "            return torch.isfinite(loss).item()\n",
    "        \n",
    "        def test_mae_loss():\n",
    "            criterion = nn.L1Loss()\n",
    "            loss = criterion(pred, target)\n",
    "            return torch.isfinite(loss).item()\n",
    "        \n",
    "        def test_huber_loss():\n",
    "            criterion = SafeHuberLoss()\n",
    "            loss = criterion(pred, target)\n",
    "            return torch.isfinite(loss).item()\n",
    "        \n",
    "        def test_combined_loss():\n",
    "            criterion = SafeCombinedLoss()\n",
    "            loss = criterion(pred, target)\n",
    "            return torch.isfinite(loss).item()\n",
    "        \n",
    "        def test_extreme_values():\n",
    "            extreme_pred = torch.tensor([1e10, -1e10, float('nan')]).to(self.device)\n",
    "            extreme_target = torch.tensor([1.0, 1.0, 1.0]).to(self.device)\n",
    "            criterion = SafeCombinedLoss()\n",
    "            try:\n",
    "                loss = criterion(extreme_pred, extreme_target)\n",
    "                return torch.isfinite(loss).item()\n",
    "            except:\n",
    "                return False\n",
    "        \n",
    "        self._run_test(\"MSE Loss\", test_mse_loss)\n",
    "        self._run_test(\"MAE Loss\", test_mae_loss)\n",
    "        self._run_test(\"Huber Loss\", test_huber_loss)\n",
    "        self._run_test(\"Combined Loss\", test_combined_loss)\n",
    "        self._run_test(\"Loss Handles Extreme Values\", test_extreme_values)\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TEST CATEGORY 6: STABILITY\n",
    "    # ========================================================================\n",
    "    \n",
    "    def test_stability(self):\n",
    "        \"\"\"Test model stability with mini training run\"\"\"\n",
    "        \n",
    "        print(\"6Ô∏è‚É£  STABILITY TESTS (Mini Training)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        def test_single_epoch_training():\n",
    "            \"\"\"Run 1 epoch to test stability\"\"\"\n",
    "            try:\n",
    "                # Get data dimensions\n",
    "                sample_batch = next(iter(self.train_loader))\n",
    "                num_features = sample_batch[1].shape[1]\n",
    "                \n",
    "                # Create small model\n",
    "                model = create_stable_model(\n",
    "                    backbone_name='efficientnet_b0',\n",
    "                    num_features=num_features,\n",
    "                    dropout=0.3\n",
    "                )\n",
    "                model = model.to(self.device)\n",
    "                model.train()\n",
    "                \n",
    "                # Setup training\n",
    "                criterion = SafeCombinedLoss()\n",
    "                optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "                \n",
    "                # Train for 5 batches\n",
    "                losses = []\n",
    "                for batch_idx, (images, features, prices) in enumerate(self.train_loader):\n",
    "                    if batch_idx >= 5:\n",
    "                        break\n",
    "                    \n",
    "                    images = images.to(self.device)\n",
    "                    features = features.to(self.device)\n",
    "                    prices = prices.to(self.device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(images, features)\n",
    "                    loss = criterion(outputs, prices)\n",
    "                    \n",
    "                    if not torch.isfinite(loss):\n",
    "                        return False\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    losses.append(loss.item())\n",
    "                \n",
    "                # Check all losses are finite\n",
    "                return all(np.isfinite(losses))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      Error: {str(e)[:50]}\")\n",
    "                return False\n",
    "        \n",
    "        def test_validation_pass():\n",
    "            \"\"\"Test validation loop\"\"\"\n",
    "            try:\n",
    "                sample_batch = next(iter(self.train_loader))\n",
    "                num_features = sample_batch[1].shape[1]\n",
    "                \n",
    "                model = create_stable_model(\n",
    "                    backbone_name='efficientnet_b0',\n",
    "                    num_features=num_features\n",
    "                )\n",
    "                model = model.to(self.device)\n",
    "                model.eval()\n",
    "                \n",
    "                criterion = SafeCombinedLoss()\n",
    "                \n",
    "                val_losses = []\n",
    "                with torch.no_grad():\n",
    "                    for batch_idx, (images, features, prices) in enumerate(self.val_loader):\n",
    "                        if batch_idx >= 3:\n",
    "                            break\n",
    "                        \n",
    "                        images = images.to(self.device)\n",
    "                        features = features.to(self.device)\n",
    "                        prices = prices.to(self.device)\n",
    "                        \n",
    "                        outputs = model(images, features)\n",
    "                        loss = criterion(outputs, prices)\n",
    "                        \n",
    "                        if not torch.isfinite(loss):\n",
    "                            return False\n",
    "                        \n",
    "                        val_losses.append(loss.item())\n",
    "                \n",
    "                return all(np.isfinite(val_losses))\n",
    "                \n",
    "            except:\n",
    "                return False\n",
    "        \n",
    "        def test_gradient_flow():\n",
    "            \"\"\"Test gradients are flowing\"\"\"\n",
    "            try:\n",
    "                sample_batch = next(iter(self.train_loader))\n",
    "                num_features = sample_batch[1].shape[1]\n",
    "                \n",
    "                model = create_stable_model('efficientnet_b0', num_features=num_features)\n",
    "                model = model.to(self.device)\n",
    "                \n",
    "                images, features, prices = sample_batch\n",
    "                images = images.to(self.device, dtype=torch.float32)\n",
    "                features = features.to(self.device, dtype=torch.float32)\n",
    "                prices = prices.to(self.device, dtype=torch.float32)\n",
    "                \n",
    "                outputs = model(images, features)\n",
    "                loss = outputs.mean()\n",
    "                loss.backward()\n",
    "                \n",
    "                # Check if gradients exist and are finite\n",
    "                has_grads = False\n",
    "                for param in model.parameters():\n",
    "                    if param.grad is not None and torch.isfinite(param.grad).all():\n",
    "                        has_grads = True\n",
    "                        break\n",
    "                \n",
    "                return has_grads\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      Error: {str(e)[:50]}\")\n",
    "                return False\n",
    "        \n",
    "        self._run_test(\"Single Epoch Training\", test_single_epoch_training)\n",
    "        self._run_test(\"Validation Pass\", test_validation_pass)\n",
    "        self._run_test(\"Gradient Flow\", test_gradient_flow)\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SUMMARY\n",
    "    # ========================================================================\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print comprehensive test summary\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìä TEST SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        pass_rate = (self.passed_tests / self.total_tests * 100) if self.total_tests > 0 else 0\n",
    "        \n",
    "        print(f\"\\n‚úÖ Passed: {self.passed_tests}/{self.total_tests} tests ({pass_rate:.1f}%)\")\n",
    "        print(f\"‚ùå Failed: {self.total_tests - self.passed_tests}/{self.total_tests} tests\")\n",
    "        \n",
    "        if pass_rate == 100:\n",
    "            print(f\"\\nüéâ ALL TESTS PASSED! Ready to train 21 models!\")\n",
    "            print(f\"   System is STABLE and READY for production training.\")\n",
    "        elif pass_rate >= 90:\n",
    "            print(f\"\\n‚úÖ MOSTLY READY ({pass_rate:.0f}% pass rate)\")\n",
    "            print(f\"   Minor issues detected but training should work.\")\n",
    "        elif pass_rate >= 75:\n",
    "            print(f\"\\n‚ö†Ô∏è  NEEDS ATTENTION ({pass_rate:.0f}% pass rate)\")\n",
    "            print(f\"   Some issues detected. Review failures before training.\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå NOT READY ({pass_rate:.0f}% pass rate)\")\n",
    "            print(f\"   Critical issues detected. Fix errors before training.\")\n",
    "        \n",
    "        # Print failed tests\n",
    "        failed_tests = [name for name, result in self.test_results.items() \n",
    "                       if result not in [\"PASS\", \"N/A\"]]\n",
    "        \n",
    "        if failed_tests:\n",
    "            print(f\"\\n‚ö†Ô∏è  Failed Tests:\")\n",
    "            for test in failed_tests:\n",
    "                print(f\"   - {test}: {self.test_results[test]}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# COMPLETE 21 MODEL TRAINING PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def train_21_robust_models(train_loader, val_loader, test_loader, device='cuda'):\n",
    "    \"\"\"\n",
    "    Complete pipeline: Test ‚Üí Train 21 Models ‚Üí Evaluate\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"üè†\"*40)\n",
    "    print(\"HOUSE PRICE PREDICTION - 21 MODEL ENSEMBLE\")\n",
    "    print(\"üè†\"*40 + \"\\n\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 1: PRE-TRAINING VALIDATION\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"STEP 1: PRE-TRAINING VALIDATION\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    validator = PreTrainingValidator(train_loader, val_loader, test_loader, device)\n",
    "    all_tests_passed = validator.run_all_tests()\n",
    "    \n",
    "    if not all_tests_passed:\n",
    "        response = input(\"\\n‚ö†Ô∏è  Some tests failed. Continue anyway? (yes/no): \")\n",
    "        if response.lower() != 'yes':\n",
    "            print(\"‚ùå Training cancelled. Please fix errors and try again.\")\n",
    "            return None, None, None\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2: DEFINE 21+ MODELS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\nSTEP 2: DEFINING 21 MODEL ARCHITECTURES\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    model_names = [\n",
    "        # EfficientNet Family (5 models) - Best for house images\n",
    "        'efficientnet_b0',\n",
    "        'efficientnet_b1',\n",
    "        'efficientnet_b2',\n",
    "        'efficientnet_b3',\n",
    "        'efficientnet_b4',\n",
    "        \n",
    "        # ResNet Family (4 models) - Stable baseline\n",
    "        'resnet50',\n",
    "        'resnet101',\n",
    "        'resnet152',\n",
    "        'wide_resnet50_2',\n",
    "        \n",
    "        # ConvNeXt (3 models) - Modern architecture\n",
    "        'convnext_tiny',\n",
    "        'convnext_small',\n",
    "        'convnext_base',\n",
    "        \n",
    "        # DenseNet (2 models) - Dense connections\n",
    "        'densenet121',\n",
    "        'densenet169',\n",
    "        \n",
    "        # MobileNet (2 models) - Efficient\n",
    "        'mobilenet_v2',\n",
    "        'mobilenet_v3_large',\n",
    "        \n",
    "        # RegNet (3 models) - Regularized networks\n",
    "        'regnet_y_400mf',\n",
    "        'regnet_y_800mf',\n",
    "        'regnet_y_1_6gf',\n",
    "        \n",
    "        # Others (2 models)\n",
    "        'shufflenet_v2_x1_0',\n",
    "        'mnasnet1_0'\n",
    "    ]\n",
    "    \n",
    "    print(f\"üìã Total models to train: {len(model_names)}\")\n",
    "    print(f\"üì¶ Models: {', '.join(model_names[:5])}... (and {len(model_names)-5} more)\")\n",
    "    \n",
    "    # Estimate training time\n",
    "    avg_time_per_model = 10  # minutes (estimate)\n",
    "    total_time_estimate = len(model_names) * avg_time_per_model\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Estimated training time:\")\n",
    "    print(f\"   Per model: ~{avg_time_per_model} minutes\")\n",
    "    print(f\"   Total: ~{total_time_estimate} minutes ({total_time_estimate/60:.1f} hours)\")\n",
    "    \n",
    "    response = input(f\"\\nüöÄ Ready to train {len(model_names)} models? (yes/no): \")\n",
    "    if response.lower() != 'yes':\n",
    "        print(\"‚ùå Training cancelled.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 3: TRAIN ENSEMBLE\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\\nSTEP 3: TRAINING ENSEMBLE\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    trained_models, all_results, trainer = run_ensemble_training(\n",
    "        model_names=model_names,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 4: FINAL ANALYSIS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\\nSTEP 4: FINAL ANALYSIS\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    if len(all_results) > 0:\n",
    "        # Find best model\n",
    "        valid_results = [r for r in all_results if r.get('test_r2', 0) > 0]\n",
    "        \n",
    "        if len(valid_results) > 0:\n",
    "            best_model = max(valid_results, key=lambda x: x['test_r2'])\n",
    "            \n",
    "            print(f\"üèÜ BEST MODEL: {best_model['model_name']}\")\n",
    "            print(f\"   R¬≤ Score: {best_model['test_r2']:.4f}\")\n",
    "            print(f\"   RMSE: ${best_model['test_rmse']:,.0f}\")\n",
    "            print(f\"   MAE: ${best_model['test_mae']:,.0f}\")\n",
    "            print(f\"   Training Time: {best_model['training_time']/60:.2f} min\")\n",
    "            \n",
    "            # Ensemble prediction (average of top 5 models)\n",
    "            top_5 = sorted(valid_results, key=lambda x: x['test_r2'], reverse=True)[:5]\n",
    "            avg_r2 = np.mean([m['test_r2'] for m in top_5])\n",
    "            avg_rmse = np.mean([m['test_rmse'] for m in top_5])\n",
    "            \n",
    "            print(f\"\\nüîù TOP 5 ENSEMBLE:\")\n",
    "            print(f\"   Average R¬≤: {avg_r2:.4f}\")\n",
    "            print(f\"   Average RMSE: ${avg_rmse:,.0f}\")\n",
    "            \n",
    "            print(f\"\\n‚úÖ Training complete! Check '{trainer.session_dir}' for all outputs.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéâ ENSEMBLE TRAINING PIPELINE COMPLETE\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return trained_models, all_results, trainer\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Complete execution:\n",
    "    1. Run pre-training tests\n",
    "    2. Train 21 models\n",
    "    3. Generate comprehensive analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assuming you have these defined from previous stages:\n",
    "    # - train_loader\n",
    "    # - val_loader  \n",
    "    # - test_loader\n",
    "    # - device\n",
    "    \n",
    "    trained_models, all_results, trainer = train_21_robust_models(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ ALL DONE! Check the output directory for:\")\n",
    "    print(\"   - Model checkpoints\")\n",
    "    print(\"   - Training logs\")\n",
    "    print(\"   - Performance visualizations\")\n",
    "    print(\"   - JSON results for each model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c72138fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîÑ RESTARTING TRAINING WITH STABILITY FIXES\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# STEP 1: Update get_model function\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Option A: Quick patch - replace get_model with get_model_stable\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtypes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m original_get_model = \u001b[43mget_model\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpatched_get_model\u001b[39m(model_name, num_features=\u001b[32m5\u001b[39m, **kwargs):\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Patched version that uses StableHousePriceModel\"\"\"\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'get_model' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RESTART TRAINING - With All Stability Fixes\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîÑ RESTARTING TRAINING WITH STABILITY FIXES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Update get_model function\n",
    "# ============================================================================\n",
    "\n",
    "# Option A: Quick patch - replace get_model with get_model_stable\n",
    "import types\n",
    "\n",
    "original_get_model = get_model\n",
    "\n",
    "def patched_get_model(model_name, num_features=5, **kwargs):\n",
    "    \"\"\"Patched version that uses StableHousePriceModel\"\"\"\n",
    "    try:\n",
    "        return get_model_stable(model_name, num_features)\n",
    "    except:\n",
    "        # Fallback to original if stable version fails\n",
    "        return original_get_model(model_name, num_features, **kwargs)\n",
    "\n",
    "# Replace globally\n",
    "get_model = patched_get_model\n",
    "print(\"‚úÖ Patched get_model to use stable version\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Use CONSERVATIVE model list (best performers)\n",
    "# ============================================================================\n",
    "\n",
    "# Start with most stable models\n",
    "conservative_models = [\n",
    "    'ResNet50',           # Very stable\n",
    "    'ResNet101',          # Very stable\n",
    "    'DenseNet121',        # Stable\n",
    "    'DenseNet169',        # Stable\n",
    "    'EfficientNetB0',     # Stable\n",
    "    'EfficientNetB3',     # Moderate\n",
    "    'MobileNetV2',        # Stable\n",
    "    'VGG16',              # Stable but slow\n",
    "]\n",
    "\n",
    "print(f\"\\nüìä Training {len(conservative_models)} conservative models\")\n",
    "print(\"   These models are less likely to have NaN/Inf issues\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Train with monitoring\n",
    "# ============================================================================\n",
    "\n",
    "def train_with_monitoring(model_names, max_failures=3):\n",
    "    \"\"\"Train models with failure monitoring\"\"\"\n",
    "    \n",
    "    successful_models = []\n",
    "    failed_models = []\n",
    "    \n",
    "    trained_models, all_results, trainer = run_ensemble_training(\n",
    "        model_names=model_names,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Check results\n",
    "    for result in all_results:\n",
    "        if result.get('test_r2', 0) > 0.5:  # Reasonable R¬≤\n",
    "            successful_models.append(result['model_name'])\n",
    "        else:\n",
    "            failed_models.append(result['model_name'])\n",
    "    \n",
    "    print(f\"\\nüìä Training Summary:\")\n",
    "    print(f\"   ‚úÖ Successful: {len(successful_models)}\")\n",
    "    print(f\"   ‚ùå Failed/Poor: {len(failed_models)}\")\n",
    "    \n",
    "    if len(successful_models) > 0:\n",
    "        print(f\"\\nüèÜ Good models:\")\n",
    "        for name in successful_models:\n",
    "            print(f\"      - {name}\")\n",
    "    \n",
    "    if len(failed_models) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Problematic models:\")\n",
    "        for name in failed_models:\n",
    "            print(f\"      - {name}\")\n",
    "    \n",
    "    return trained_models, all_results, trainer\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Run training\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "trained_models, all_results, trainer = train_with_monitoring(\n",
    "    model_names=conservative_models\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Show best results\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "if len(all_results) > 0:\n",
    "    # Filter out failed models\n",
    "    valid_results = [r for r in all_results if r.get('test_r2', 0) > 0.1]\n",
    "    \n",
    "    if len(valid_results) > 0:\n",
    "        df = pd.DataFrame([{\n",
    "            'Model': r['model_name'],\n",
    "            'R¬≤ Score': r.get('test_r2', 0),\n",
    "            'RMSE': r.get('test_rmse', float('inf')),\n",
    "            'MAE': r.get('test_mae', float('inf')),\n",
    "            'Training Time (min)': r.get('training_time', 0) / 60\n",
    "        } for r in valid_results])\n",
    "        \n",
    "        df = df.sort_values('R¬≤ Score', ascending=False)\n",
    "        \n",
    "        print(\"\\nüèÜ TOP PERFORMING MODELS:\")\n",
    "        print(\"=\"*80)\n",
    "        print(df.to_string(index=False))\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        best_model = df.iloc[0]\n",
    "        print(f\"\\n‚≠ê Best Model: {best_model['Model']}\")\n",
    "        print(f\"   R¬≤ Score: {best_model['R¬≤ Score']:.4f}\")\n",
    "        print(f\"   RMSE: ${best_model['RMSE']:,.2f}\")\n",
    "        print(f\"   MAE: ${best_model['MAE']:,.2f}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No models achieved good performance (R¬≤ > 0.1)\")\n",
    "        print(\"   This suggests a fundamental issue with:\")\n",
    "        print(\"   1. Data normalization/scaling\")\n",
    "        print(\"   2. Price target distribution\")\n",
    "        print(\"   3. Feature quality\")\n",
    "        \n",
    "        print(\"\\nüîç Debugging suggestions:\")\n",
    "        print(\"   - Check if prices are normalized correctly\")\n",
    "        print(\"   - Verify image preprocessing\")\n",
    "        print(\"   - Ensure no NaN in input data\")\n",
    "        print(\"   - Check if price range is reasonable\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No models completed training\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Next steps\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìù NEXT STEPS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len([r for r in all_results if r.get('test_r2', 0) > 0.5]) >= 3:\n",
    "    print(\"\\n‚úÖ Good! You have working models. Now you can:\")\n",
    "    print(\"   1. Add more models from model_names_diverse\")\n",
    "    print(\"   2. Create ensemble predictions\")\n",
    "    print(\"   3. Fine-tune hyperparameters\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Few/no good models. You should:\")\n",
    "    print(\"   1. Check data preprocessing code\")\n",
    "    print(\"   2. Verify price normalization\")\n",
    "    print(\"   3. Examine a few training samples manually\")\n",
    "    print(\"   4. Try even lower learning rates (0.0001)\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a25b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60da2f15",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ca388f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Total models to train: 21\n",
      "üñ•Ô∏è  Device: cuda\n",
      "üìÅ Session Directory: model_outputs\\20251126_014813\n",
      "\n",
      "================================================================================\n",
      "üöÄ Starting Ensemble Training Session\n",
      "================================================================================\n",
      "üìä Total models to train: 21\n",
      "üìÅ Session ID: 20251126_014813\n",
      "üíæ Output directory: model_outputs\\20251126_014813\n",
      "üñ•Ô∏è  Device: cuda\n",
      "================================================================================\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [1/21] üèóÔ∏è  Training: ResNet50\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for ResNet50:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training ResNet50 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: ResNet50...\n",
      "‚úÖ Model created successfully (0.30s)\n",
      "   üìä Total parameters: 26,121,667\n",
      "   üéØ Trainable parameters: 26,121,667\n",
      "   üíæ Model size: 99.65 MB\n",
      "\n",
      "üéØ Loss Function: HUBER\n",
      "‚öôÔ∏è  Optimizer: ADAMW\n",
      "üìà Scheduler: COSINE\n",
      "üîÑ Stochastic Weight Averaging: ENABLED\n",
      "‚ö° Mixed Precision Training: ENABLED\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Epochs: 50\n",
      "   Learning Rate: 0.003\n",
      "   Batch Size: 32\n",
      "   Gradient Accumulation Steps: 1\n",
      "   Effective Batch Size: 32\n",
      "   Warmup Epochs: 3\n",
      "   MixUp: ENABLED\n",
      "   Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]:   0%|                                                                        | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error training ResNet50: mat1 and mat2 shapes cannot be multiplied (65536x1 and 2048x128)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 1/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 1\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.1min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [2/21] üèóÔ∏è  Training: ResNet101\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for ResNet101:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: combined\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training ResNet101 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: ResNet101...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 279, in train_model_robust\n",
      "    outputs = model(mixed_images, mixed_features)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\479995792.py\", line 287, in forward\n",
      "    attention_weights = self.channel_attention(cnn_features.unsqueeze(-1)).squeeze(-1)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (65536x1 and 2048x128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (0.36s)\n",
      "   üìä Total parameters: 45,113,795\n",
      "   üéØ Trainable parameters: 45,113,795\n",
      "   üíæ Model size: 172.10 MB\n",
      "\n",
      "üéØ Loss Function: COMBINED\n",
      "‚öôÔ∏è  Optimizer: RADAM\n",
      "üìà Scheduler: PLATEAU\n",
      "\n",
      "‚ùå Error training ResNet101: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 2/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 2\n",
      "‚è±Ô∏è  Elapsed: 0.0min | ETA: 0.1min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [3/21] üèóÔ∏è  Training: ResNet152\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for ResNet152:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: combined\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training ResNet152 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: ResNet152...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 172, in train_model_robust\n",
      "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to C:\\Users\\LEGION/.cache\\torch\\hub\\checkpoints\\resnet152-394f9c45.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 230M/230M [00:32<00:00, 7.42MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (33.52s)\n",
      "   üìä Total parameters: 60,757,443\n",
      "   üéØ Trainable parameters: 60,757,443\n",
      "   üíæ Model size: 231.77 MB\n",
      "\n",
      "üéØ Loss Function: COMBINED\n",
      "‚öôÔ∏è  Optimizer: ADAMW\n",
      "üìà Scheduler: COSINE\n",
      "üîÑ Stochastic Weight Averaging: ENABLED\n",
      "‚ö° Mixed Precision Training: ENABLED\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Epochs: 50\n",
      "   Learning Rate: 0.003\n",
      "   Batch Size: 32\n",
      "   Gradient Accumulation Steps: 1\n",
      "   Effective Batch Size: 32\n",
      "   Warmup Epochs: 3\n",
      "   MixUp: DISABLED\n",
      "   Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]:   0%|                                                                        | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error training ResNet152: mat1 and mat2 shapes cannot be multiplied (65536x1 and 2048x128)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 3/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 3\n",
      "‚è±Ô∏è  Elapsed: 0.6min | ETA: 3.4min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [4/21] üèóÔ∏è  Training: EfficientNetB0\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for EfficientNetB0:\n",
      "   lr: 0.002\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 2\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training EfficientNetB0 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: EfficientNetB0...\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\LEGION/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 279, in train_model_robust\n",
      "    outputs = model(mixed_images, mixed_features)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\479995792.py\", line 287, in forward\n",
      "    attention_weights = self.channel_attention(cnn_features.unsqueeze(-1)).squeeze(-1)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (65536x1 and 2048x128)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:03<00:00, 7.12MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (3.28s)\n",
      "   üìä Total parameters: 5,907,663\n",
      "   üéØ Trainable parameters: 5,907,663\n",
      "   üíæ Model size: 22.54 MB\n",
      "\n",
      "üéØ Loss Function: HUBER\n",
      "‚öôÔ∏è  Optimizer: ADAMW\n",
      "üìà Scheduler: COSINE\n",
      "üîÑ Stochastic Weight Averaging: ENABLED\n",
      "‚ö° Mixed Precision Training: ENABLED\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Epochs: 50\n",
      "   Learning Rate: 0.002\n",
      "   Batch Size: 32\n",
      "   Gradient Accumulation Steps: 2\n",
      "   Effective Batch Size: 64\n",
      "   Warmup Epochs: 3\n",
      "   MixUp: DISABLED\n",
      "   Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]:   0%|                                                                        | 0/36 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 279, in train_model_robust\n",
      "    outputs = model(mixed_images, mixed_features)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\479995792.py\", line 287, in forward\n",
      "    attention_weights = self.channel_attention(cnn_features.unsqueeze(-1)).squeeze(-1)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (40960x1 and 1280x80)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 172, in train_model_robust\n",
      "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error training EfficientNetB0: mat1 and mat2 shapes cannot be multiplied (40960x1 and 1280x80)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 4/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 4\n",
      "‚è±Ô∏è  Elapsed: 0.6min | ETA: 2.7min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [5/21] üèóÔ∏è  Training: EfficientNetB3\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for EfficientNetB3:\n",
      "   lr: 0.002\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 2\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training EfficientNetB3 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: EfficientNetB3...\n",
      "‚úÖ Model created successfully (0.14s)\n",
      "   üìä Total parameters: 12,817,803\n",
      "   üéØ Trainable parameters: 12,817,803\n",
      "   üíæ Model size: 48.90 MB\n",
      "\n",
      "üéØ Loss Function: HUBER\n",
      "‚öôÔ∏è  Optimizer: RADAM\n",
      "üìà Scheduler: PLATEAU\n",
      "\n",
      "‚ùå Error training EfficientNetB3: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 5/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 5\n",
      "‚è±Ô∏è  Elapsed: 0.6min | ETA: 2.1min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [6/21] üèóÔ∏è  Training: EfficientNetB5\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for EfficientNetB5:\n",
      "   lr: 0.002\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 2\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training EfficientNetB5 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: EfficientNetB5...\n",
      "‚úÖ Model created successfully (0.41s)\n",
      "   üìä Total parameters: 30,954,419\n",
      "   üéØ Trainable parameters: 30,954,419\n",
      "   üíæ Model size: 118.08 MB\n",
      "\n",
      "üéØ Loss Function: HUBER\n",
      "‚öôÔ∏è  Optimizer: ADAMW\n",
      "üìà Scheduler: COSINE\n",
      "üîÑ Stochastic Weight Averaging: ENABLED\n",
      "‚ö° Mixed Precision Training: ENABLED\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Epochs: 50\n",
      "   Learning Rate: 0.002\n",
      "   Batch Size: 32\n",
      "   Gradient Accumulation Steps: 2\n",
      "   Effective Batch Size: 64\n",
      "   Warmup Epochs: 3\n",
      "   MixUp: ENABLED\n",
      "   Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]:   0%|                                                                        | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error training EfficientNetB5: mat1 and mat2 shapes cannot be multiplied (65536x1 and 2048x128)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 6/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 6\n",
      "‚è±Ô∏è  Elapsed: 0.7min | ETA: 1.6min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [7/21] üèóÔ∏è  Training: EfficientNetV2\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for EfficientNetV2:\n",
      "   lr: 0.002\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 2\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training EfficientNetV2 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: EfficientNetV2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 279, in train_model_robust\n",
      "    outputs = model(mixed_images, mixed_features)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\479995792.py\", line 287, in forward\n",
      "    attention_weights = self.channel_attention(cnn_features.unsqueeze(-1)).squeeze(-1)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (65536x1 and 2048x128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (0.21s)\n",
      "   üìä Total parameters: 22,077,603\n",
      "   üéØ Trainable parameters: 22,077,603\n",
      "   üíæ Model size: 84.22 MB\n",
      "\n",
      "üéØ Loss Function: HUBER\n",
      "‚öôÔ∏è  Optimizer: ADAMW\n",
      "üìà Scheduler: COSINE\n",
      "üîÑ Stochastic Weight Averaging: ENABLED\n",
      "‚ö° Mixed Precision Training: ENABLED\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Epochs: 50\n",
      "   Learning Rate: 0.002\n",
      "   Batch Size: 32\n",
      "   Gradient Accumulation Steps: 2\n",
      "   Effective Batch Size: 64\n",
      "   Warmup Epochs: 3\n",
      "   MixUp: DISABLED\n",
      "   Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]:   0%|                                                                        | 0/36 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 279, in train_model_robust\n",
      "    outputs = model(mixed_images, mixed_features)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\479995792.py\", line 287, in forward\n",
      "    attention_weights = self.channel_attention(cnn_features.unsqueeze(-1)).squeeze(-1)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (40960x1 and 1280x80)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 172, in train_model_robust\n",
      "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error training EfficientNetV2: mat1 and mat2 shapes cannot be multiplied (40960x1 and 1280x80)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 7/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 7\n",
      "‚è±Ô∏è  Elapsed: 0.7min | ETA: 1.4min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [8/21] üèóÔ∏è  Training: DenseNet121\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for DenseNet121:\n",
      "   lr: 0.003\n",
      "   num_epochs: 45\n",
      "   loss_type: combined\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: False\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training DenseNet121 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: DenseNet121...\n",
      "‚úÖ Model created successfully (0.10s)\n",
      "   üìä Total parameters: 8,648,899\n",
      "   üéØ Trainable parameters: 8,648,899\n",
      "   üíæ Model size: 32.99 MB\n",
      "\n",
      "üéØ Loss Function: COMBINED\n",
      "‚öôÔ∏è  Optimizer: RADAM\n",
      "üìà Scheduler: PLATEAU\n",
      "\n",
      "‚ùå Error training DenseNet121: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 8/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 8\n",
      "‚è±Ô∏è  Elapsed: 0.7min | ETA: 1.1min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [9/21] üèóÔ∏è  Training: DenseNet169\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for DenseNet169:\n",
      "   lr: 0.003\n",
      "   num_epochs: 45\n",
      "   loss_type: combined\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: False\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training DenseNet169 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: DenseNet169...\n",
      "‚úÖ Model created successfully (0.16s)\n",
      "   üìä Total parameters: 14,722,923\n",
      "   üéØ Trainable parameters: 14,722,923\n",
      "   üíæ Model size: 56.16 MB\n",
      "\n",
      "üéØ Loss Function: COMBINED\n",
      "‚öôÔ∏è  Optimizer: RADAM\n",
      "üìà Scheduler: PLATEAU\n",
      "\n",
      "‚ùå Error training DenseNet169: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 9/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 9\n",
      "‚è±Ô∏è  Elapsed: 0.7min | ETA: 0.9min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [10/21] üèóÔ∏è  Training: DenseNet201\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for DenseNet201:\n",
      "   lr: 0.003\n",
      "   num_epochs: 45\n",
      "   loss_type: huber\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: False\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training DenseNet201 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: DenseNet201...\n",
      "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to C:\\Users\\LEGION/.cache\\torch\\hub\\checkpoints\\densenet201-c1103571.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 172, in train_model_robust\n",
      "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77.4M/77.4M [00:12<00:00, 6.29MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (13.53s)\n",
      "   üìä Total parameters: 20,577,403\n",
      "   üéØ Trainable parameters: 20,577,403\n",
      "   üíæ Model size: 78.50 MB\n",
      "\n",
      "üéØ Loss Function: HUBER\n",
      "‚öôÔ∏è  Optimizer: RADAM\n",
      "üìà Scheduler: PLATEAU\n",
      "\n",
      "‚ùå Error training DenseNet201: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 10/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 10\n",
      "‚è±Ô∏è  Elapsed: 0.9min | ETA: 1.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [11/21] üèóÔ∏è  Training: MobileNetV2\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for MobileNetV2:\n",
      "   lr: 0.004\n",
      "   num_epochs: 45\n",
      "   loss_type: mae\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: False\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training MobileNetV2 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: MobileNetV2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 172, in train_model_robust\n",
      "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (0.15s)\n",
      "   üìä Total parameters: 4,123,987\n",
      "   üéØ Trainable parameters: 4,123,987\n",
      "   üíæ Model size: 15.73 MB\n",
      "\n",
      "üéØ Loss Function: MAE\n",
      "‚öôÔ∏è  Optimizer: RADAM\n",
      "üìà Scheduler: PLATEAU\n",
      "\n",
      "‚ùå Error training MobileNetV2: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 11/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 11\n",
      "‚è±Ô∏è  Elapsed: 0.9min | ETA: 0.8min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [12/21] üèóÔ∏è  Training: MobileNetV3Large\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for MobileNetV3Large:\n",
      "   lr: 0.004\n",
      "   num_epochs: 45\n",
      "   loss_type: mae\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: onecycle\n",
      "   use_swa: False\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training MobileNetV3Large with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: MobileNetV3Large...\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to C:\\Users\\LEGION/.cache\\torch\\hub\\checkpoints\\mobilenet_v3_large-8738ca79.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 172, in train_model_robust\n",
      "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21.1M/21.1M [00:03<00:00, 7.26MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (3.53s)\n",
      "   üìä Total parameters: 4,872,067\n",
      "   üéØ Trainable parameters: 4,872,067\n",
      "   üíæ Model size: 18.59 MB\n",
      "\n",
      "üéØ Loss Function: MAE\n",
      "‚öôÔ∏è  Optimizer: ADAMW\n",
      "üìà Scheduler: ONECYCLE\n",
      "‚ö° Mixed Precision Training: ENABLED\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Epochs: 45\n",
      "   Learning Rate: 0.004\n",
      "   Batch Size: 32\n",
      "   Gradient Accumulation Steps: 1\n",
      "   Effective Batch Size: 32\n",
      "   Warmup Epochs: 3\n",
      "   MixUp: ENABLED\n",
      "   Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/45 [Train]:   0%|                                                                        | 0/36 [00:01<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 279, in train_model_robust\n",
      "    outputs = model(mixed_images, mixed_features)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\479995792.py\", line 287, in forward\n",
      "    attention_weights = self.channel_attention(cnn_features.unsqueeze(-1)).squeeze(-1)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (30720x1 and 1280x80)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error training MobileNetV3Large: mat1 and mat2 shapes cannot be multiplied (30720x1 and 1280x80)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 12/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 12\n",
      "‚è±Ô∏è  Elapsed: 1.0min | ETA: 0.7min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [13/21] üèóÔ∏è  Training: VGG16\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for VGG16:\n",
      "   lr: 0.005\n",
      "   num_epochs: 40\n",
      "   loss_type: huber\n",
      "   optimizer_type: sgd\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training VGG16 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: VGG16...\n",
      "‚úÖ Model created successfully (1.88s)\n",
      "   üìä Total parameters: 139,497,795\n",
      "   üéØ Trainable parameters: 139,497,795\n",
      "   üíæ Model size: 532.14 MB\n",
      "\n",
      "üéØ Loss Function: HUBER\n",
      "‚öôÔ∏è  Optimizer: SGD\n",
      "üìà Scheduler: COSINE\n",
      "üîÑ Stochastic Weight Averaging: ENABLED\n",
      "‚ö° Mixed Precision Training: ENABLED\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Epochs: 40\n",
      "   Learning Rate: 0.005\n",
      "   Batch Size: 32\n",
      "   Gradient Accumulation Steps: 1\n",
      "   Effective Batch Size: 32\n",
      "   Warmup Epochs: 3\n",
      "   MixUp: ENABLED\n",
      "   Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Train]:   0%|                                                                        | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error training VGG16: mat1 and mat2 shapes cannot be multiplied (131072x1 and 4096x256)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 13/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 13\n",
      "‚è±Ô∏è  Elapsed: 1.0min | ETA: 0.6min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [14/21] üèóÔ∏è  Training: VGG19\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for VGG19:\n",
      "   lr: 0.005\n",
      "   num_epochs: 40\n",
      "   loss_type: mse\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training VGG19 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: VGG19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 279, in train_model_robust\n",
      "    outputs = model(mixed_images, mixed_features)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\479995792.py\", line 287, in forward\n",
      "    attention_weights = self.channel_attention(cnn_features.unsqueeze(-1)).squeeze(-1)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (131072x1 and 4096x256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (1.75s)\n",
      "   üìä Total parameters: 144,807,491\n",
      "   üéØ Trainable parameters: 144,807,491\n",
      "   üíæ Model size: 552.40 MB\n",
      "\n",
      "üéØ Loss Function: MSE\n",
      "‚öôÔ∏è  Optimizer: RADAM\n",
      "üìà Scheduler: PLATEAU\n",
      "\n",
      "‚ùå Error training VGG19: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 14/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 14\n",
      "‚è±Ô∏è  Elapsed: 1.1min | ETA: 0.5min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [15/21] üèóÔ∏è  Training: ViT_B16\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for ViT_B16:\n",
      "   lr: 0.001\n",
      "   num_epochs: 60\n",
      "   loss_type: combined\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 2\n",
      "   warmup_epochs: 5\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training ViT_B16 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: ViT_B16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 172, in train_model_robust\n",
      "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (1.22s)\n",
      "   üìä Total parameters: 87,305,011\n",
      "   üéØ Trainable parameters: 87,305,011\n",
      "   üíæ Model size: 333.04 MB\n",
      "\n",
      "üéØ Loss Function: COMBINED\n",
      "‚öôÔ∏è  Optimizer: ADAMW\n",
      "üìà Scheduler: COSINE\n",
      "üîÑ Stochastic Weight Averaging: ENABLED\n",
      "‚ö° Mixed Precision Training: ENABLED\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Epochs: 60\n",
      "   Learning Rate: 0.001\n",
      "   Batch Size: 32\n",
      "   Gradient Accumulation Steps: 2\n",
      "   Effective Batch Size: 64\n",
      "   Warmup Epochs: 5\n",
      "   MixUp: ENABLED\n",
      "   Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 [Train]:   0%|                                                                        | 0/36 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 279, in train_model_robust\n",
      "    outputs = model(mixed_images, mixed_features)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\479995792.py\", line 287, in forward\n",
      "    attention_weights = self.channel_attention(cnn_features.unsqueeze(-1)).squeeze(-1)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (24576x1 and 768x48)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error training ViT_B16: mat1 and mat2 shapes cannot be multiplied (24576x1 and 768x48)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 15/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 15\n",
      "‚è±Ô∏è  Elapsed: 1.1min | ETA: 0.4min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [16/21] üèóÔ∏è  Training: ViT_B32\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for ViT_B32:\n",
      "   lr: 0.001\n",
      "   num_epochs: 60\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 2\n",
      "   warmup_epochs: 5\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training ViT_B32 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: ViT_B32...\n",
      "‚úÖ Model created successfully (1.27s)\n",
      "   üìä Total parameters: 88,961,587\n",
      "   üéØ Trainable parameters: 88,961,587\n",
      "   üíæ Model size: 339.36 MB\n",
      "\n",
      "üéØ Loss Function: HUBER\n",
      "‚öôÔ∏è  Optimizer: ADAMW\n",
      "üìà Scheduler: COSINE\n",
      "üîÑ Stochastic Weight Averaging: ENABLED\n",
      "‚ö° Mixed Precision Training: ENABLED\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Epochs: 60\n",
      "   Learning Rate: 0.001\n",
      "   Batch Size: 32\n",
      "   Gradient Accumulation Steps: 2\n",
      "   Effective Batch Size: 64\n",
      "   Warmup Epochs: 5\n",
      "   MixUp: DISABLED\n",
      "   Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 [Train]:   0%|                                                                        | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error training ViT_B32: mat1 and mat2 shapes cannot be multiplied (24576x1 and 768x48)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 16/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 16\n",
      "‚è±Ô∏è  Elapsed: 1.1min | ETA: 0.3min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [17/21] üèóÔ∏è  Training: SwinTransformer\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for SwinTransformer:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: combined\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training SwinTransformer with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: SwinTransformer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 279, in train_model_robust\n",
      "    outputs = model(mixed_images, mixed_features)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\479995792.py\", line 287, in forward\n",
      "    attention_weights = self.channel_attention(cnn_features.unsqueeze(-1)).squeeze(-1)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (24576x1 and 768x48)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (0.68s)\n",
      "   üìä Total parameters: 29,025,709\n",
      "   üéØ Trainable parameters: 29,025,709\n",
      "   üíæ Model size: 110.72 MB\n",
      "\n",
      "üéØ Loss Function: COMBINED\n",
      "‚öôÔ∏è  Optimizer: RADAM\n",
      "üìà Scheduler: PLATEAU\n",
      "\n",
      "‚ùå Error training SwinTransformer: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 17/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 17\n",
      "‚è±Ô∏è  Elapsed: 1.1min | ETA: 0.3min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [18/21] üèóÔ∏è  Training: ConvNeXt\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for ConvNeXt:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: combined\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training ConvNeXt with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: ConvNeXt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 172, in train_model_robust\n",
      "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (0.60s)\n",
      "   üìä Total parameters: 30,095,483\n",
      "   üéØ Trainable parameters: 30,095,483\n",
      "   üíæ Model size: 114.81 MB\n",
      "\n",
      "üéØ Loss Function: COMBINED\n",
      "‚öôÔ∏è  Optimizer: ADAMW\n",
      "üìà Scheduler: COSINE\n",
      "üîÑ Stochastic Weight Averaging: ENABLED\n",
      "‚ö° Mixed Precision Training: ENABLED\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Epochs: 50\n",
      "   Learning Rate: 0.003\n",
      "   Batch Size: 32\n",
      "   Gradient Accumulation Steps: 1\n",
      "   Effective Batch Size: 32\n",
      "   Warmup Epochs: 3\n",
      "   MixUp: DISABLED\n",
      "   Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]:   0%|                                                                        | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error training ConvNeXt: mat1 and mat2 shapes cannot be multiplied (32000x1 and 768x48)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 18/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 18\n",
      "‚è±Ô∏è  Elapsed: 1.1min | ETA: 0.2min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [19/21] üèóÔ∏è  Training: RegNetY\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for RegNetY:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: huber\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: True\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training RegNetY with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: RegNetY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 279, in train_model_robust\n",
      "    outputs = model(mixed_images, mixed_features)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\479995792.py\", line 287, in forward\n",
      "    attention_weights = self.channel_attention(cnn_features.unsqueeze(-1)).squeeze(-1)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (32000x1 and 768x48)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (0.14s)\n",
      "   üìä Total parameters: 5,191,246\n",
      "   üéØ Trainable parameters: 5,191,246\n",
      "   üíæ Model size: 19.80 MB\n",
      "\n",
      "üéØ Loss Function: HUBER\n",
      "‚öôÔ∏è  Optimizer: ADAMW\n",
      "üìà Scheduler: COSINE\n",
      "üîÑ Stochastic Weight Averaging: ENABLED\n",
      "‚ö° Mixed Precision Training: ENABLED\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Epochs: 50\n",
      "   Learning Rate: 0.003\n",
      "   Batch Size: 32\n",
      "   Gradient Accumulation Steps: 1\n",
      "   Effective Batch Size: 32\n",
      "   Warmup Epochs: 3\n",
      "   MixUp: ENABLED\n",
      "   Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]:   0%|                                                                        | 0/36 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 279, in train_model_robust\n",
      "    outputs = model(mixed_images, mixed_features)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\479995792.py\", line 287, in forward\n",
      "    attention_weights = self.channel_attention(cnn_features.unsqueeze(-1)).squeeze(-1)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (14080x1 and 440x27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error training RegNetY: mat1 and mat2 shapes cannot be multiplied (14080x1 and 440x27)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 19/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 19\n",
      "‚è±Ô∏è  Elapsed: 1.1min | ETA: 0.1min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [20/21] üèóÔ∏è  Training: WideResNet\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for WideResNet:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: combined\n",
      "   optimizer_type: radam\n",
      "   scheduler_type: plateau\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training WideResNet with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: WideResNet...\n",
      "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to C:\\Users\\LEGION/.cache\\torch\\hub\\checkpoints\\wide_resnet50_2-95faca4d.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 132M/132M [00:17<00:00, 7.98MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created successfully (19.11s)\n",
      "   üìä Total parameters: 69,447,875\n",
      "   üéØ Trainable parameters: 69,447,875\n",
      "   üíæ Model size: 264.92 MB\n",
      "\n",
      "üéØ Loss Function: COMBINED\n",
      "‚öôÔ∏è  Optimizer: RADAM\n",
      "üìà Scheduler: PLATEAU\n",
      "\n",
      "‚ùå Error training WideResNet: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 20/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 20\n",
      "‚è±Ô∏è  Elapsed: 1.5min | ETA: 0.1min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# [21/21] üèóÔ∏è  Training: Inception-V3\n",
      "################################################################################\n",
      "\n",
      "üìã Configuration for Inception-V3:\n",
      "   lr: 0.003\n",
      "   num_epochs: 50\n",
      "   loss_type: combined\n",
      "   optimizer_type: adamw\n",
      "   scheduler_type: cosine\n",
      "   use_swa: True\n",
      "   use_mixup: False\n",
      "   gradient_accumulation_steps: 1\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ Training Inception-V3 with ROBUST Configuration\n",
      "======================================================================\n",
      "‚úì Number of features: 5\n",
      "üì¶ Creating model architecture: Inception-V3...\n",
      "‚ùå Error creating model: The parameter 'aux_logits' expected value True but got False instead.\n",
      "\n",
      "‚ùå Error training Inception-V3: The parameter 'aux_logits' expected value True but got False instead.\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìà Progress: 21/21 models completed\n",
      "‚úÖ Successful: 0 | ‚ùå Failed: 21\n",
      "‚è±Ô∏è  Elapsed: 1.5min | ETA: 0.0min\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üéâ Ensemble Training Completed!\n",
      "================================================================================\n",
      "‚úÖ Successfully trained: 0/21 models\n",
      "‚ùå Failed: 21/21 models\n",
      "‚è±Ô∏è  Total training time: 1.47 minutes (0.02 hours)\n",
      "üìÅ All outputs saved to: model_outputs\\20251126_014813\n",
      "================================================================================\n",
      "\n",
      "üìä Generating training summary and visualizations...\n",
      "\n",
      "‚ö†Ô∏è  No models trained successfully!\n",
      "\n",
      "================================================================================\n",
      "üìä TRAINING COMPLETE - RESULTS SUMMARY\n",
      "================================================================================\n",
      "üìÅ All outputs saved to: model_outputs\\20251126_014813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 172, in train_model_robust\n",
      "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\4108819757.py\", line 192, in train_single_model\n",
      "    model, results = train_model_robust(\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\2022634056.py\", line 109, in train_model_robust\n",
      "    model = get_model(model_name, num_features=num_features).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_19752\\479995792.py\", line 458, in get_model\n",
      "    backbone = models.inception_v3(pretrained=True, aux_logits=False)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py\", line 142, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py\", line 228, in inner_wrapper\n",
      "    return builder(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\inception.py\", line 466, in inception_v3\n",
      "    _ovewrite_named_param(kwargs, \"aux_logits\", True)\n",
      "  File \"c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py\", line 238, in _ovewrite_named_param\n",
      "    raise ValueError(f\"The parameter '{param}' expected value {new_value} but got {kwargs[param]} instead.\")\n",
      "ValueError: The parameter 'aux_logits' expected value True but got False instead.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_outputs\\\\20251126_014813\\\\training_summary.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Load summary CSV\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m summary_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtraining_summary.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müèÜ Top 5 Models by R¬≤ Score:\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     90\u001b[39m \u001b[38;5;28mprint\u001b[39m(summary_df.head(\u001b[32m5\u001b[39m)[[\u001b[33m'\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTest R¬≤\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTest RMSE\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTraining Time (min)\u001b[39m\u001b[33m'\u001b[39m]].to_string(index=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'model_outputs\\\\20251126_014813\\\\training_summary.csv'"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE INTEGRATION - RUN THIS TO START TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Choose Your Model List\n",
    "# ============================================================================\n",
    "\n",
    "# Option A: Use your original 21 model names (compatible with old code)\n",
    "model_names = [\n",
    "    'EfficientNet', 'MobileNet-v2', 'ResNet', 'DenseNet', 'Xception',\n",
    "    'Inception-V3', 'GoogleNet', 'VGG', 'Squeeze-and-Excitation',\n",
    "    'Residual-Attention', 'WideResNet', 'Inception-ResNet-v2',\n",
    "    'Inception-V4', 'Competitive-SE', 'HRNetV2', 'FractalNet',\n",
    "    'Highway', 'AlexNet', 'NIN', 'ZFNet', 'CapsuleNet'\n",
    "]\n",
    "\n",
    "# Option B: Use extended model names for better diversity (RECOMMENDED)\n",
    "model_names_diverse = [\n",
    "    # ResNet family (3 models)\n",
    "    'ResNet50', 'ResNet101', 'ResNet152',\n",
    "    \n",
    "    # EfficientNet family (4 models)\n",
    "    'EfficientNetB0', 'EfficientNetB3', 'EfficientNetB5', 'EfficientNetV2',\n",
    "    \n",
    "    # DenseNet family (3 models)\n",
    "    'DenseNet121', 'DenseNet169', 'DenseNet201',\n",
    "    \n",
    "    # MobileNet family (2 models)\n",
    "    'MobileNetV2', 'MobileNetV3Large',\n",
    "    \n",
    "    # VGG family (2 models)\n",
    "    'VGG16', 'VGG19',\n",
    "    \n",
    "    # Vision Transformers (2 models)\n",
    "    'ViT_B16', 'ViT_B32',\n",
    "    \n",
    "    # Modern architectures (4 models)\n",
    "    'SwinTransformer', 'ConvNeXt', 'RegNetY', 'WideResNet',\n",
    "    \n",
    "    # Classic (1 model)\n",
    "    'Inception-V3'\n",
    "]  # Total: 21 models\n",
    "\n",
    "print(f'üìä Total models to train: {len(model_names_diverse)}')\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Run Complete Training Pipeline\n",
    "# ============================================================================\n",
    "\n",
    "# Make sure you have:\n",
    "# - train_loader (DataLoader for training data)\n",
    "# - val_loader (DataLoader for validation data)\n",
    "# - test_loader (DataLoader for test data)\n",
    "# - device (cuda or cpu)\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'üñ•Ô∏è  Device: {device}')\n",
    "\n",
    "# Run ensemble training with the improved pipeline\n",
    "trained_models, all_results, trainer = run_ensemble_training(\n",
    "    model_names=model_names_diverse,  # Or use model_names for original\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Access Results\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('üìä TRAINING COMPLETE - RESULTS SUMMARY')\n",
    "print('='*80)\n",
    "\n",
    "# Get session directory\n",
    "session_dir = trainer.session_dir\n",
    "print(f'üìÅ All outputs saved to: {session_dir}')\n",
    "\n",
    "# Load summary CSV\n",
    "import pandas as pd\n",
    "summary_df = pd.read_csv(session_dir / 'training_summary.csv')\n",
    "\n",
    "print('\\nüèÜ Top 5 Models by R¬≤ Score:')\n",
    "print(summary_df.head(5)[['Model', 'Test R¬≤', 'Test RMSE', 'Training Time (min)']].to_string(index=False))\n",
    "\n",
    "# Best model\n",
    "best_model_name = summary_df.iloc[0]['Model']\n",
    "best_r2 = summary_df.iloc[0]['Test R¬≤']\n",
    "best_rmse = summary_df.iloc[0]['Test RMSE']\n",
    "\n",
    "print(f'\\n‚≠ê Best Model: {best_model_name}')\n",
    "print(f'   R¬≤ Score: {best_r2:.4f}')\n",
    "print(f'   RMSE: ${best_rmse:,.2f}')\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Create Ensemble Predictions (Optional)\n",
    "# ============================================================================\n",
    "\n",
    "def create_ensemble_predictions(trained_models, test_loader, top_k=10):\n",
    "    \"\"\"\n",
    "    Create ensemble predictions using top K models\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'\\nüîÆ Creating ensemble predictions using top {top_k} models...')\n",
    "    \n",
    "    # Get top K model names\n",
    "    top_models = summary_df.head(top_k)['Model'].tolist()\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    for model_name in top_models:\n",
    "        if model_name in trained_models:\n",
    "            model = trained_models[model_name]\n",
    "            model.eval()\n",
    "            \n",
    "            batch_predictions = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, features, _ in test_loader:\n",
    "                    images = images.to(device)\n",
    "                    features = features.to(device)\n",
    "                    \n",
    "                    preds = model(images, features)\n",
    "                    batch_predictions.extend(preds.cpu().numpy())\n",
    "            \n",
    "            all_predictions.append(batch_predictions)\n",
    "    \n",
    "    # Average predictions\n",
    "    import numpy as np\n",
    "    ensemble_preds = np.mean(all_predictions, axis=0)\n",
    "    \n",
    "    print(f'‚úÖ Ensemble predictions created using {len(all_predictions)} models')\n",
    "    \n",
    "    return ensemble_preds\n",
    "\n",
    "# Create ensemble predictions\n",
    "ensemble_predictions = create_ensemble_predictions(\n",
    "    trained_models=trained_models,\n",
    "    test_loader=test_loader,\n",
    "    top_k=10  # Use top 10 models\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Evaluate Ensemble Performance\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Get actual test targets\n",
    "test_targets = []\n",
    "with torch.no_grad():\n",
    "    for _, _, prices in test_loader:\n",
    "        test_targets.extend(prices.numpy())\n",
    "\n",
    "test_targets = np.array(test_targets)\n",
    "\n",
    "# Denormalize predictions and targets\n",
    "test_preds_norm = ensemble_predictions.reshape(-1, 1)\n",
    "test_targets_norm = test_targets.reshape(-1, 1)\n",
    "\n",
    "test_preds = test_loader.dataset.price_scaler.inverse_transform(test_preds_norm).flatten()\n",
    "test_targets_real = test_loader.dataset.price_scaler.inverse_transform(test_targets_norm).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "ensemble_r2 = r2_score(test_targets_real, test_preds)\n",
    "ensemble_rmse = np.sqrt(mean_squared_error(test_targets_real, test_preds))\n",
    "ensemble_mae = mean_absolute_error(test_targets_real, test_preds)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('üéØ ENSEMBLE PERFORMANCE (Top 10 Models Average)')\n",
    "print('='*80)\n",
    "print(f'R¬≤ Score:  {ensemble_r2:.4f}')\n",
    "print(f'RMSE:      ${ensemble_rmse:,.2f}')\n",
    "print(f'MAE:       ${ensemble_mae:,.2f}')\n",
    "print('='*80)\n",
    "\n",
    "# Compare with best single model\n",
    "improvement = ((ensemble_r2 - best_r2) / best_r2) * 100\n",
    "print(f'\\nüìà Improvement over best single model: {improvement:+.2f}%')\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Visualize Predictions\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(test_targets_real, test_preds, alpha=0.5, s=20)\n",
    "axes[0].plot([test_targets_real.min(), test_targets_real.max()], \n",
    "             [test_targets_real.min(), test_targets_real.max()], \n",
    "             'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Price ($)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Predicted Price ($)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title(f'Ensemble Predictions (R¬≤={ensemble_r2:.4f})', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals = test_targets_real - test_preds\n",
    "axes[1].scatter(test_preds, residuals, alpha=0.5, s=20)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Price ($)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Residuals ($)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Residual Plot', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "prediction_plot_path = session_dir / 'ensemble_predictions.png'\n",
    "plt.savefig(prediction_plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f'\\nüìä Prediction plots saved to: {prediction_plot_path}')\n",
    "plt.show()\n",
    "\n",
    "print('\\n‚úÖ ALL DONE! üéâ')\n",
    "print(f'üìÅ Check {session_dir} for all outputs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
